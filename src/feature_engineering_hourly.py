"""
Feature Engineering (Hourly) ‚Äî Safe for 120-step forecasting

M·ª•c ti√™u:
- D√πng d·ªØ li·ªáu theo GI·ªú ƒë·ªÉ d·ª± b√°o nhi·ªát ƒë·ªô 120 gi·ªù ti·∫øp theo (5 ng√†y).
- Tr√°nh leak t∆∞∆°ng lai: rolling lu√¥n shift(1), drop to√†n b·ªô "lag 0" sau khi t·∫°o ƒë·∫∑c tr∆∞ng.
- Cho ph√©p ch·∫°y 2 ch·∫ø ƒë·ªô:
    * ar_only=True  : ch·ªâ ƒë·∫∑c tr∆∞ng t·ª´ th·ªùi gian + lag/rolling c·ªßa TARGET (an to√†n khi kh√¥ng c√≥ d·ª± b√°o exogenous).
    * ar_only=False : cho ph√©p th√™m m·ªôt s·ªë ƒë·∫∑c tr∆∞ng kh√≠ t∆∞·ª£ng kh√°c (n·∫øu b·∫°n c√≥ d·ªØ b√°o exogenous cho t∆∞∆°ng lai).

H√†m ch√≠nh:
- feature_engineering_hourly(df, target="temp", forecast_horizon=1, ar_only=True, lags=(...), windows=(...))

Utils k√®m theo:
- make_multi_horizon_targets(df, target='temp', horizons=120): t·∫°o 120 c·ªôt nh√£n T+1..T+120.
"""

from __future__ import annotations
import pandas as pd
import numpy as np
from typing import Iterable, List, Tuple, Optional, Sequence


def _ensure_datetime_index(df: pd.DataFrame):
    "ƒê·∫£m b·∫£o index lf Datetime index v·∫ß ƒë∆∞·ª£c sort tƒÉng d·∫ßn"
    if not isinstance(df.index,pd.DatetimeIndex):
        if 'datetime' in df.columns:
            df = df.copy()
            df['datetime'] = pd.to_datetime(df['datetime'],errors = 'coerce')
            df = df.set_index('datetime')
        else:
            raise ValueError('DataIndex dont have datetime columns')
    return df.sort_index()

def _drop_future_features(df:pd.DataFrame,cols_to_drop:Sequence[str],keep:Sequence[str]):
    """
    Lo·∫°i b·ªè c√°c feature 'lag 0' (t·ª©c l√† c√°c c·ªôt g·ªëc, c√≥ nguy c∆° leak),
    nh∆∞ng gi·ªØ l·∫°i m·ªôt s·ªë c·ªôt c·∫ßn thi·∫øt trong keep (vd: target hi·ªán t·∫°i ƒë·ªÉ t·∫°o lag ti·∫øp theo).
    """
    cols_to_drop = list(cols_to_drop)
    for i in keep:
        if i in cols_to_drop:
            cols_to_drop.remove(i)
    return df.drop(columns=cols_to_drop,errors='ignore')
# ----------------------------- #
# Time features (hourly)
# ----------------------------- #

def create_date_feature_hourly(df:pd.DataFrame):
    """
    T·∫°o ƒë·∫∑c tr∆∞ng theo GI·ªú:
    - hour, hour_sin, hour_cos
    - weekday (0-6), month (1-12) + cyclical month
    (Kh√¥ng ƒë·ªông t·ªõi sunrise/sunset ƒë·ªÉ tr√°nh r·ªëi d·ªØ li·ªáu theo gi·ªù)
    """
    df = _ensure_datetime_index(df).copy()
    dt = df.index

    df["hour"] = dt.hour
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)

    df["weekday"] = dt.weekday
    df["month"] = dt.month
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)
    
    # Seasonal signal over the year
    df["dayofyear"] = dt.dayofyear
    df["dayofyear_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
    df["dayofyear_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)


    return df

# ----------------------------- #
# Lag & Rolling (hourly)
# ----------------------------- #

def create_lag_rolling_hourly(
    df: pd.DataFrame,
    columns: Sequence[str],
    lags: Sequence[int] = (1, 3, 6, 12, 24, 48, 72),
    windows: Sequence[int] = (3, 6, 12, 24, 48),
    forecast_horizon: int = 1,
    fill_method: str = "bfill",
) -> pd.DataFrame:
    """
    T·∫°o lag v√† rolling cho nhi·ªÅu c·ªôt theo GI·ªú.
    - Lu√¥n shift(1) cho rolling ƒë·ªÉ tr√°nh leak.
    - Ch·ªâ t·∫°o c√°c lag >= forecast_horizon.

    fill_method: 'bfill' | 'ffill' | 'mean'
    """
    df = _ensure_datetime_index(df).copy()
    columns = [c for c in columns if c in df.columns]
    if not columns:
        return df

    valid_lags = [l for l in lags if l >= forecast_horizon]

    new_parts = []

    if valid_lags:
        lag_frames = {
            f"{col}_lag_{l}": df[col].shift(l) for col in columns for l in valid_lags
        }
        new_parts.append(pd.concat(lag_frames, axis=1))

    roll_mean = {
        f"{col}_roll_mean_{w}": df[col].shift(1).rolling(window=w, min_periods=1).mean()
        for col in columns for w in windows
    }
    roll_std = {
        f"{col}_roll_std_{w}": df[col].shift(1).rolling(window=w, min_periods=1).std()
        for col in columns for w in windows
    }
    new_parts.append(pd.concat({**roll_mean, **roll_std}, axis=1))

    out = pd.concat([df] + new_parts, axis=1)

    if fill_method == "bfill":
        out = out.bfill()
    elif fill_method == "ffill":
        out = out.ffill()
    elif fill_method == "mean":
        out = out.fillna(out.mean(numeric_only=True))
    else:
        raise ValueError("fill_method must be one of: 'bfill' | 'ffill' | 'mean'")

    return out

# ----------------------------- #
# Specific features (safe set)
# ----------------------------- #

def create_specific_features_hourly(
        df:pd.DataFrame,
        target: str = 'temp'
):
    """
    M·ªôt s·ªë ƒë·∫∑c tr∆∞ng ƒë∆°n gi·∫£n, an to√†n cho 120-step:
    - temp_diff_1h, temp_diff_3h (gradient ng·∫Øn h·∫°n)
    - N·∫øu c√≥ tempmax/tempmin theo gi·ªù th√¨ temp_range (kh√¥ng b·∫Øt bu·ªôc)
    - dew_spread (n·∫øu c√≥ 'dew')
    """
    df = df.copy()
    if target in df.columns:
        df[f"{target}_diff_1h"] = df[target].diff(1)
        df[f"{target}_diff_3h"] = df[target].diff(3)

    if{'tempmax','tempmin'}.issubset(df.columns):
        df['temp_range'] = df['tempmax'] - df['tempmin']

    if 'dew' in df.columns:
        base = df['tempmin'] if 'tempmin' in df.columns else df.get(target,None)
        if base is not None:
            df['dew_spread'] = base - df['dew']
        
    return df

# ----------------------------- #
# MAIN API
# ----------------------------- #

def feature_engineering_hourly(
    df: pd.DataFrame,
    target: str = "temp",
    forecast_horizon: int = 1,
    ar_only: bool = True,
    lags: Sequence[int] = (1, 3, 6, 12, 24, 48, 72),
    windows: Sequence[int] = (3, 6, 12, 24, 48),
    fill_method: str = "bfill",
    extra_columns: Optional[Sequence[str]] = None,
) -> pd.DataFrame:
    """
    T·ªïng h·ª£p to√†n b·ªô FE HOURLY.

    Tham s·ªë:
    - target            : t√™n c·ªôt m·ª•c ti√™u (m·∫∑c ƒë·ªãnh 'temp')
    - forecast_horizon  : kho·∫£ng nh√¨n tr∆∞·ªõc t·ªëi thi·ªÉu (>=1)
    - ar_only           : True -> ch·ªâ d√πng ƒë·∫∑c tr∆∞ng th·ªùi gian + lag/rolling c·ªßa target
                          False -> cho ph√©p th√™m ƒë·∫∑c tr∆∞ng kh√°c (n·∫øu c√≥ exogenous forecast)
    - lags, windows     : t·∫≠p lag/rolling theo gi·ªù
    - fill_method       : 'bfill' | 'ffill' | 'mean'
    - extra_columns     : (t√πy ch·ªçn) danh s√°ch c·ªôt exogenous b·∫°n mu·ªën t·∫°o lag/rolling (khi ar_only=False)

    Tr·∫£ v·ªÅ:
    - DataFrame ƒë√£ sinh ƒë·∫∑c tr∆∞ng v√† lo·∫°i b·ªè to√†n b·ªô c·ªôt "lag 0" (tr·ª´ c√°c c·ªôt c·∫ßn gi·ªØ).
    """
    if forecast_horizon < 1:
        raise ValueError("forecast_horizon must be >= 1")

    df = _ensure_datetime_index(df).copy()

    # 1) Time features (hourly)
    df = create_date_feature_hourly(df)

    # 2) Specific safe features
    df = create_specific_features_hourly(df, target=target)

    # 3) ƒê√°nh d·∫•u c√°c c·ªôt 'lag 0' ƒë·ªÉ drop sau c√πng (tr√°nh leak)
    lag0_cols = df.columns.copy()

    # 4) Lag & Rolling
    if ar_only:
        cols_for_lr = [c for c in [target] if c in df.columns]
    else:
        # cho ph√©p th√™m exogenous n·∫øu ƒë√£ c√≥ (vd c√≥ d·ª± b√°o t∆∞∆°ng lai)
        cols_for_lr = [target]
        if extra_columns:
            cols_for_lr += [c for c in extra_columns if c in df.columns]
        # lo·∫°i tr√πng
        cols_for_lr = list(dict.fromkeys(cols_for_lr))

    df = create_lag_rolling_hourly(
        df,
        columns=cols_for_lr,
        lags=lags,
        windows=windows,
        forecast_horizon=forecast_horizon,
        fill_method=fill_method,
    )

    # 5) Drop to√†n b·ªô c·ªôt g·ªëc (lag 0) ƒë·ªÉ kh√¥ng d√πng th√¥ng tin hi·ªán t·∫°i c·ªßa t∆∞∆°ng lai
    keep_cols = [target]  # v·∫´n gi·ªØ target hi·ªán t·∫°i ƒë·ªÉ ti·∫øp t·ª•c t·∫°o lag ·ªü b∆∞·ªõc kh√°c n·∫øu c·∫ßn
    df = _drop_future_features(df, cols_to_drop=lag0_cols, keep=keep_cols)

    # 6) B·ªè c√°c h√†ng ƒë·∫ßu ti√™n b·ªã NaN do lag/rolling (n·∫øu c√≤n)
    df = df.dropna(how="any")

    return df

# ----------------------------- #
# Multi-horizon label maker
# ----------------------------- #

def make_multi_horizon_targets(
    df: pd.DataFrame,
    target: str = "temp",
    horizons: int = 120,
) -> pd.DataFrame:
    """
    T·∫°o 120 nh√£n t∆∞∆°ng lai: target_t+1 ... target_t+H
    L∆∞u √Ω: G·ªçi SAU khi ƒë√£ t·∫°o xong ƒë·∫∑c tr∆∞ng (FE) ƒë·ªÉ tr√°nh r·ªõt d·ªØ li·ªáu kh√¥ng c·∫ßn thi·∫øt.
    """
    if target not in df.columns:
        raise KeyError(f"Target '{target}' not found in DataFrame.")
    df = df.copy()
    for h in range(1, horizons + 1):
        df[f"{target}_t+{h}"] = df[target].shift(-h)
    # B·ªè c√°c h√†ng cu·ªëi kh√¥ng ƒë·ªß nh√£n
    return df.iloc[:-horizons].dropna(how="any")

def _ensure_dtindex(df: pd.DataFrame, tz: str | None = None) -> pd.DataFrame:
    if not isinstance(df.index, pd.DatetimeIndex):
        if "datetime" in df.columns:
            df = df.copy()
            df["datetime"] = pd.to_datetime(df["datetime"], errors="coerce", utc=True)
            df = df.set_index("datetime")
        else:
            raise ValueError("C·∫ßn DatetimeIndex ho·∫∑c c·ªôt 'datetime'.")
    df = df.sort_index()
    if tz is not None:
        if df.index.tz is None:
            df.index = df.index.tz_localize("UTC")
        df.index = df.index.tz_convert(tz)
    return df

def build_hourly_to_daily_dataset(
    hourly: pd.DataFrame,
    target_col: str = "temp",           # c·ªôt ƒë·ªÉ t·∫°o nh√£n daily (vd temp)
    target_daily_func: str = "mean",    # "mean" | "max" | "min" | "median" | "sum"
    horizon_days: int = 1,              # d·ª± b√°o ng√†y t+1 (ho·∫∑c t+H)
    feature_cols: list[str] | None = None,  # None = d√πng t·∫•t c·∫£ c·ªôt numeric l√†m ƒë·∫∑c tr∆∞ng
    window_hours: tuple[int, ...] = (6, 12, 24, 36, 48, 72),  # lookback k·∫øt th√∫c t·∫°i 23:59 c·ªßa ng√†y t-1
    agg_funcs: tuple[str, ...] = ("mean", "std", "min", "max", "median", "last"),
    tz: str | None = None,
    add_quality_flags: bool = True,     # c·ªù ch·∫•t l∆∞·ª£ng (thi·∫øu gi·ªù, %missing,‚Ä¶)
    add_calendar_daily: bool = True,    # ƒë·∫∑c tr∆∞ng theo ng√†y (doy, dow, month ‚Ä¶)
) -> pd.DataFrame:
    """
    T·∫°o m·ªôt d√≤ng/1 ng√†y:
      - ƒê·∫∑c tr∆∞ng: t·ªïng h·ª£p t·ª´ c√°c *hourly features* c·ªßa c√°c kho·∫£ng lookback k·∫øt th√∫c ·ªü 23:59 ng√†y *t-1*.
      - Nh√£n: aggregate(target_col) c·ªßa ng√†y *t + horizon_days*.
    Kh√¥ng d√πng d·ªØ li·ªáu c·ªßa ng√†y c·∫ßn d·ª± b√°o tr·ªü ƒëi => kh√¥ng r√≤ r·ªâ.
    """

    H = _ensure_dtindex(hourly, tz=tz).copy()

    # Ch·ªçn c·ªôt ƒë·∫∑c tr∆∞ng
    if feature_cols is None:
        feature_cols = [c for c in H.columns if np.issubdtype(H[c].dtype, np.number)]
    if target_col not in H.columns:
        raise ValueError(f"Kh√¥ng th·∫•y target_col='{target_col}' trong d·ªØ li·ªáu.")

    # ===== 1) T·∫°o nh√£n daily ·ªü ng√†y t =====
    # daily_target[t] = agg(target_col trong ng√†y t)
    daily_target = (
        H[[target_col]]
        .resample("D")
        .agg({target_col: target_daily_func})
        .rename(columns={target_col: f"{target_col}_daily_{target_daily_func}"})
    )

    # D·ªãch nh√£n v·ªÅ t+horizon_days ƒë·ªÉ d·ª± b√°o t∆∞∆°ng lai
    y_col = f"{target_col}_daily_{target_daily_func}_t+{horizon_days}d"
    daily_target[y_col] = daily_target.iloc[:, 0].shift(-horizon_days)
    daily_target = daily_target[[y_col]]

    # ===== 2) T·∫°o khung ng√†y g·ªëc (m·ªói ng√†y 1 d√≤ng) =====
    days = H.resample("D").size().to_frame("hours_present")
    days["hours_missing"] = 24 - days["hours_present"].clip(upper=24)

    # ===== 3) T·ªïng h·ª£p HOURLY FEATURES th√†nh DAILY FEATURES (k·∫øt th√∫c ·ªü t-1) =====
    # Ta s·∫Ω t·∫°o ƒë·∫∑c tr∆∞ng cho *ng√†y t* b·∫±ng c√°ch nh√¨n "c·ª≠a s·ªï k·∫øt th√∫c t·∫°i 23:59 c·ªßa t-1".
    # C√°ch l√†m: ƒë∆∞a m·ªëc v·ªÅ 00:00 c·ªßa t, r·ªìi l·∫•y d·ªØ li·ªáu tr∆∞·ªõc m·ªëc ƒë√≥.
    day_index = days.index  # m·ªëc 00:00 m·ªói ng√†y (t)
    feats_list = []

    # Precompute: t√≠ch l≈©y (expensive) -> d√πng rolling on fixed timedelta is messy; ta d√πng mask theo kho·∫£ng th·ªùi gian.
    # L√†m g·ªçn: v·ªõi m·ªói ng√†y t, v·ªõi m·ªói W gi·ªù, l·∫•y H.loc[(t - Wh, t)) v√† t√≠nh agg.
    # ƒê·ªÉ ch·∫°y nhanh h∆°n tr√™n d·ªØ li·ªáu l·ªõn, c√≥ th·ªÉ vectorize b·∫±ng resample->expanding, nh∆∞ng ƒë∆°n gi·∫£n & an to√†n tr∆∞·ªõc.
    for t in day_index:
        # m·ªëc tr√°i/ph·∫£i cho t·ª´ng W: (t - W gi·ªù) .. (t - 1 gi·ªù)
        row = {}
        # C·ªù ch·∫•t l∆∞·ª£ng theo ng√†y t-1 (ri√™ng cho 24h g·∫ßn nh·∫•t)
        if add_quality_flags:
            last24 = H.loc[t - pd.Timedelta(hours=24): t - pd.Timedelta(seconds=1)]
            row["q_last24_hours_present"] = len(last24)
            row["q_last24_hours_missing"] = 24 - min(len(last24), 24)

        # L·∫∑p t·ª´ng c·ª≠a s·ªï
        for W in window_hours:
            start = t - pd.Timedelta(hours=W)
            end = t  # exclusive
            block = H.loc[start : t - pd.Timedelta(seconds=1)]
            if block.empty:
                # fill NaNs ƒë·ªÉ sau dropna
                for c in feature_cols:
                    for f in agg_funcs:
                        row[f"{c}_win{W}h_{f}"] = np.nan
                continue

            # T√≠nh s·ªë gi·ªù hi·ªán di·ªán c·ªßa block (cho c·ªù ch·∫•t l∆∞·ª£ng theo W)
            if add_quality_flags:
                row[f"q_win{W}h_hours_present"] = len(block)
                row[f"q_win{W}h_hours_missing"] = W - min(len(block), W)

            # T√≠nh c√°c ph√©p g·ªôp tr√™n t·ª´ng c·ªôt feature
            for c in feature_cols:
                series = block[c].dropna()
                for f in agg_funcs:
                    if f == "mean":
                        val = series.mean() if not series.empty else np.nan
                    elif f == "std":
                        val = series.std(ddof=1) if len(series) > 1 else np.nan
                    elif f == "min":
                        val = series.min() if not series.empty else np.nan
                    elif f == "max":
                        val = series.max() if not series.empty else np.nan
                    elif f == "median":
                        val = series.median() if not series.empty else np.nan
                    elif f == "last":
                        # gi√° tr·ªã *cu·ªëi c√πng tr∆∞·ªõc m·ªëc t* (t-Œµ)
                        val = series.iloc[-1] if not series.empty else np.nan
                    elif f == "sum":
                        val = series.sum() if not series.empty else np.nan
                    elif f == "p10":
                        val = series.quantile(0.10) if len(series) > 0 else np.nan
                    elif f == "p90":
                        val = series.quantile(0.90) if len(series) > 0 else np.nan
                    else:
                        raise ValueError(f"agg_funcs kh√¥ng h·ªó tr·ª£ '{f}'")
                    row[f"{c}_win{W}h_{f}"] = val

            # V√≠ d·ª• ƒë·∫∑c tr∆∞ng tu·ª≥ bi·∫øn h·ªØu √≠ch cho th·ªùi ti·∫øt (n·∫øu c√≥ c√°c c·ªôt n√†y)
            if {"precip", "rain", "snow"} & set(block.columns):
                precip_like = [c for c in ("precip", "rain", "snow") if c in block.columns]
                tot = block[precip_like].sum(axis=1)
                row[f"precip_win{W}h_sum"] = tot.sum()
                row[f"precip_win{W}h_hours>0"] = int((tot > 0).sum())

        feats_list.append(pd.Series(row, name=t))

    X = pd.DataFrame(feats_list).sort_index()

    # ===== 4) Th√™m calendar features theo NG√ÄY t (kh√¥ng g√¢y leak) =====
    if add_calendar_daily:
        dt = X.index
        cal = pd.DataFrame(index=dt)
        cal["doy"] = dt.dayofyear
        cal["doy_sin"] = np.sin(2 * np.pi * cal["doy"] / 366.0)
        cal["doy_cos"] = np.cos(2 * np.pi * cal["doy"] / 366.0)
        cal["dow"] = dt.dayofweek
        cal["is_weekend"] = (cal["dow"] >= 5).astype(int)
        cal["month"] = dt.month
        cal["month_sin"] = np.sin(2 * np.pi * cal["month"] / 12.0)
        cal["month_cos"] = np.cos(2 * np.pi * cal["month"] / 12.0)
        X = X.join(cal, how="left")

    # ===== 5) Gh√©p nh√£n (t+horizon_days) & l√†m s·∫°ch =====
    dataset = X.join(daily_target, how="left")
    dataset = dataset.dropna(subset=[y_col]).dropna(axis=1, how="all")  # c·ªôt to√†n NaN th√¨ b·ªè
    return dataset, y_col
if __name__ == "__main__":
    import pandas as pd

    CSV = r"data/raw data/hanoi_weather_data_hourly.csv"
    TARGET = "temp"

    df = pd.read_csv(CSV, parse_dates=["datetime"]).set_index("datetime").sort_index()

    # B·ªè ph·∫ßn hourly n·∫øu kh√¥ng c·∫ßn
    # X = feature_engineering_hourly(...)
    # XY = make_multi_horizon_targets(...)

    # Gi·ªØ l·∫°i ph·∫ßn daily th√¥i
    ds, y_col = build_hourly_to_daily_dataset(
        df,
        target_col=TARGET,
        target_daily_func="mean",
        horizon_days=1
    )

    print("‚úÖ Dataset daily:", ds.shape, "| Target:", y_col)
        # --- Save to CSV ---
    OUTPUT_CSV = r"data/hanoi_weather_daily_features.csv"
    ds.to_csv(OUTPUT_CSV, index=True)
    print(f"üíæ Saved daily dataset to {OUTPUT_CSV}")
