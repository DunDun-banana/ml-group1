{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ee4fd09",
      "metadata": {
        "id": "4ee4fd09"
      },
      "source": [
        "### I. Libary import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72ccedf",
      "metadata": {
        "id": "b72ccedf"
      },
      "outputs": [],
      "source": [
        "from clearml import Task\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import optuna\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import optuna.visualization as vis\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from clearml import Logger\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "\n",
        "from src import data_preprocessing as dp\n",
        "from src import pipeline as pl\n",
        "from src import new_feature_engineering_daily as fe\n",
        "from src import feature_selection as fs\n",
        "from src.model_evaluation import evaluate, evaluate_multi_output\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
        "\n",
        "SEED = 42 # vẫn phải chọn random của model đấy\n",
        "\n",
        "# Python, NumPy\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Hash seed cho Python interpreter (ảnh hưởng tới dict order)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# Giới hạn luồng tính toán song song (để tránh floating-point nondeterminism)\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# tạo sampler của Optuna có seed cố định\n",
        "sampler = optuna.samplers.TPESampler(seed=SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c965d253",
      "metadata": {
        "id": "c965d253"
      },
      "source": [
        "### I. Data prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6yWJckbZ1lsS"
      },
      "id": "6yWJckbZ1lsS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a9465b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a9465b",
        "outputId": "2c30ea4e-1217-4985-f2c9-56d7a4003695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded data with shape: (3660, 33)\n",
            "Dropped column: 'description'\n",
            "Dropped column: 'icon'\n",
            "Dropped column: 'stations'\n",
            "Dropped column: 'name'\n"
          ]
        }
      ],
      "source": [
        "# 1. Load raw Data\n",
        "df = dp.load_data(r'/content/Hanoi Daily 10 years.csv')\n",
        "\n",
        "# 2. basic preprocessing for all data set\n",
        "df = dp.basic_preprocessing(df=df)\n",
        "\n",
        "# 3. Chia train, test theo thời gian (80/20)\n",
        "train_size = 0.8\n",
        "n = len(df)\n",
        "\n",
        "train_df = df.iloc[:int(train_size * n)]\n",
        "test_df = df.iloc[int(train_size * n):]\n",
        "\n",
        "# 4. Fit preprocessing pipeline trên train\n",
        "pipeline1 = pl.build_preprocessing_pipeline()\n",
        "pipeline1.fit(train_df)\n",
        "\n",
        "# 5. Transform cả train và test\n",
        "train_processed = pipeline1.transform(train_df)\n",
        "test_processed = pipeline1.transform(test_df)\n",
        "\n",
        "# 6. Chia train, test theo thời gian (80/20)\n",
        "train_size = 0.8\n",
        "n = len(df)\n",
        "\n",
        "train_df = df.iloc[:int(train_size * n)]\n",
        "test_df = df.iloc[int(train_size * n):]\n",
        "\n",
        "# 7. Fit preprocessing pipeline trên train\n",
        "pipeline1 = pl.build_preprocessing_pipeline()\n",
        "pipeline1.fit(train_df)\n",
        "\n",
        "# 8. Transform cả train và test\n",
        "train_processed = pipeline1.transform(train_df)\n",
        "test_processed = pipeline1.transform(test_df)\n",
        "\n",
        "# 9. Lưu lại pipeline 1\n",
        "# joblib.dump(pipeline1, r\"pipelines\\preprocessing_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef4631b",
      "metadata": {
        "id": "4ef4631b"
      },
      "source": [
        "### II. Feature Engineering and Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d2c53a",
      "metadata": {
        "id": "a1d2c53a"
      },
      "source": [
        "### A) OVERVIEW"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc83d641",
      "metadata": {
        "id": "bc83d641"
      },
      "source": [
        "## 1. Forecasting Architectures\n",
        "\n",
        "#### **1. Recursive Strategy**\n",
        "**Method:**  \n",
        "A single model is trained to predict only one step ahead (t + 1).  \n",
        "To forecast t + 2, the model’s own prediction for t + 1 is fed back into its input features.  \n",
        "This process is repeated for each subsequent step.\n",
        "\n",
        "**Drawback:**  \n",
        "This approach is highly susceptible to **error accumulation** — any small error in the t + 1 forecast becomes part of the input for t + 2, and the errors compound over time.  \n",
        "Performance therefore degrades quickly for longer horizons.\n",
        "\n",
        "**When to use:**  \n",
        "Useful for short-term forecasts where the system dynamics are stable and small accumulated errors have minimal effect.\n",
        "\n",
        "#### **2. Multi-Output Strategy**\n",
        "**Method:**  \n",
        "A single, more complex model is trained to predict multiple future time steps (t + 1 → t + 5) simultaneously in one forward pass.\n",
        "\n",
        "**Drawback:**  \n",
        "This model acts as a **generalist** — while computationally efficient, it often struggles to optimize each specific horizon, producing good but not optimal results for any particular forecast step.\n",
        "\n",
        "**When to use:**  \n",
        "When efficiency and simultaneous multi-step outputs are more important than maximizing accuracy at a specific horizon.\n",
        "\n",
        "#### **3. Direct Strategy *(Chosen Approach)***\n",
        "**Method:**  \n",
        "Train a **separate, independent model** for each forecast horizon.  \n",
        "For example, the model for t + 3 is trained exclusively on data pairs of *(Features at time t, Target at time t + 3)*.  \n",
        "In our case, we train **five separate models**, one for each horizon (t + 1 → t + 5).\n",
        "\n",
        "**Justification:**  \n",
        "This strategy is the **most robust and accurate** for our problem.  \n",
        "It avoids recursive error propagation and allows each model to specialize in the unique temporal relationships relevant to its forecast distance.  \n",
        "Although it requires training multiple models, the gain in accuracy and reliability justifies the extra computational cost, especially since our dataset per day is relatively small.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857952ab",
      "metadata": {
        "id": "857952ab"
      },
      "source": [
        "## 2. Metrics Explanation (MAE, RMSE, R²)\n",
        "\n",
        "In this project, we evaluate our weather forecasting models using three main regression metrics: **Mean Absolute Error (MAE)**, **Root Mean Squared Error (RMSE)**, and the **Coefficient of Determination (R²)**.  \n",
        "Each metric provides a different perspective on model performance and together they give a more complete evaluation.\n",
        "\n",
        "#### **1. Mean Absolute Error (MAE)**\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "**Meaning:**  \n",
        "MAE measures the **average absolute difference** between predicted and actual values.  \n",
        "It tells us, on average, how much the predictions deviate from the true observations — regardless of direction (positive or negative).\n",
        "\n",
        "**Characteristics:**\n",
        "- Interpretable in the same unit as the target variable (e.g., °C for temperature).\n",
        "- Less sensitive to large outliers.\n",
        "- Easier to interpret and explain to non-technical audiences.\n",
        "\n",
        "#### **2. Root Mean Squared Error (RMSE)**\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$\n",
        "RMSE = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }\n",
        "$$\n",
        "\n",
        "**Meaning:**  \n",
        "RMSE measures the **square root of the average squared error**.  \n",
        "It penalizes larger errors more heavily than MAE, which makes it useful for emphasizing cases where the model performs particularly poorly.\n",
        "\n",
        "**Characteristics:**\n",
        "- Sensitive to outliers and large deviations.  \n",
        "- Provides stronger penalty for big mistakes → better for highlighting unstable models.\n",
        "- Has the same unit as the target variable (°C).\n",
        "\n",
        "\n",
        "#### **3. Coefficient of Determination (R² Score)**\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{ \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 }{ \\sum_{i=1}^{n}(y_i - \\bar{y})^2 }\n",
        "$$\n",
        "\n",
        "**Meaning:**  \n",
        "R² represents the **proportion of variance** in the target variable that can be explained by the model.  \n",
        "The closer R² is to 1, the better the model explains the data variability.\n",
        "\n",
        "**Interpretation:**\n",
        "- \\( R^2 = 1 \\): Perfect prediction.  \n",
        "- \\( R^2 = 0 \\): Model performs no better than simply predicting the mean.  \n",
        "- \\( R^2 < 0 \\): Model performs worse than predicting the mean.\n",
        "\n",
        "\n",
        "#### **4. Implementation in Our Project**\n",
        "\n",
        "We use the function `evaluate_multi_output()` defined in the `model_evaluation.py` file to compute these metrics.  \n",
        "**Inputs:**  \n",
        "- `y_true`: True target values (actual weather data).  \n",
        "- `y_pred`: Predicted values from our trained models.  \n",
        "\n",
        "**Outputs:**  \n",
        "- Dictionary containing `MAE`, `RMSE`, and `R²` scores for each forecast horizon.\n",
        "\n",
        "This allows us to evaluate each of our five direct models (t+1 → t+5) consistently and compare their performance.\n",
        "\n",
        "\n",
        "#### **5. Metric Prioritization**\n",
        "\n",
        "Although all metrics are reported for completeness, our group **prioritizes RMSE** for model optimization.\n",
        "\n",
        "**Reasoning:**\n",
        "- RMSE strongly penalizes large prediction errors, which is important for weather forecasting where a few extreme wrong predictions (e.g., 5–6°C off) can be more harmful than small consistent ones.\n",
        "- RMSE thus encourages the model to perform more consistently and handle variability better.\n",
        "\n",
        "During evaluation, we still analyze **MAE** and **R²** alongside RMSE to ensure a balanced understanding of model accuracy and reliability.\n",
        "\n",
        "\n",
        "**➡️ In short:**  \n",
        "We evaluate with all three metrics but **optimize for RMSE** to achieve a more stable and accurate forecasting performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f5cf312",
      "metadata": {
        "id": "2f5cf312"
      },
      "source": [
        "### 3. Cách đánh giá\n",
        "Ngoài việc chia train, test thì trong quá trình tuning và so sánh giữa các phương pháp mình sẽ sử dụng Cross-Val trên train. Vẽ cho t cái biểu đồ tiếp (nếu biểu đồ tổng quát có cụ thể rồi thì thôi)\n",
        "\n",
        "\n",
        "Đây là đoạn t viết để giải thích chung chung, (ai đọc thì check xem t vt đúng luôn không) cho mọi người. Người viết tóm tắt ngắn gọn lại quy trình thôi\n",
        "\n",
        "- Workflow: Trong quá trình so sánh các phương án, tuning chỉ dùng dữ liệu trên tập train (tập này sẽ được chia thành 5 cross-validation - tức 5 cặp train/ test nhỏ - và mình sẽ đánh giá mức độ dự đoán và ổn định của model trên các cặp train/ test này)\n",
        "\n",
        "=> Tìm được phương án tốt nhất rồi thì mới training lại và đánh giá lần cuối trên toàn bộ train và test set.\n",
        "\n",
        "- Phần so sánh việc drop base, hay xử lí cate: Mấy bạn viết report kết quả, Ngoài việc sử dụng (Metrics trung bình của 5 tập hay Std của 5 tập - thể hiện mức độ biến động/ ổn định giữa các fold) tìm thêm biểu đồ biểu như kiểu box plot (thầy Long) để trực quan hoá, nhớ là kèm giải thích ngắn gọn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf28fe2c",
      "metadata": {
        "id": "cf28fe2c"
      },
      "source": [
        "### 4. Nói qua Công cụ Tuning mình dùng - Nhàn\n",
        "- Optuna để tuning\n",
        "- ClearML để lưu kết quả: Chụp ảnh màn hình, xong về mục artifact mình sẽ log những gì, scalar log những gì, ... Thêm link CLearML vào đây\n",
        "\n",
        "Nhàn lên được ClearML nên viết phần này"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0c2406",
      "metadata": {
        "id": "5a0c2406"
      },
      "source": [
        "### B) Feature engineering and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f99e4980",
      "metadata": {
        "id": "f99e4980"
      },
      "source": [
        "### 1. Linear Model\n",
        "### MNG ĐỌC\n",
        "- Đang để tune riêng 5 model, Mà kết quả tune nó hơi lạ, Nhàn tune Linear (Ridge) tiếp cho t, kết quả bất lực quá thì thôi tune để lấy số liệu, với biểu đồ so sánh giúp mình đưa ra kết luận là chọn Tree(lgb) thôi\n",
        "\n",
        "- Hoàng chịu khó cop lại rồi thay lgb vào hoặc viết mới, sửa lại các kiểu tuỳ\n",
        "\n",
        "- Ai tune thì chú ý cũng chưa có mấy cái biểu đồ hình vẽ  như vis.plot_parallel_coordinate(study_grad), vis.plot_param_importances(study=study_grad), vis.plot_slice(study=study_grad). Mng cho thêm vào, tại mk cũng sẽ cần cho 1-2 cái vào report để nói về quá trình tune + kèm giải thích ngắn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24089e2c",
      "metadata": {
        "id": "24089e2c"
      },
      "outputs": [],
      "source": [
        "# Đây là mấy cái biểu đồ cũ lúc tuning mình dùng, mọi người tự ghép vào\n",
        "\n",
        "# === Vẽ biểu đồ RMSE theo trial  ===\n",
        "# fig3 = plt.figure(figsize=(7, 4))\n",
        "# plt.plot([t.value for t in study_grad.trials])\n",
        "# plt.xlabel(\"Trial\")\n",
        "# plt.ylabel(\"RMSE\")\n",
        "# plt.title(\"Optuna RMSE per Trial\")\n",
        "\n",
        "# logger_grad.report_matplotlib_figure(\n",
        "#     title=\"Optuna Performance\",\n",
        "#     series=\"RMSE Curve\",\n",
        "#     figure=fig3,\n",
        "#     iteration=len(study_grad.trials)\n",
        "# )\n",
        "# plt.close(fig3)\n",
        "\n",
        "# vis.plot_parallel_coordinate(study_grad)\n",
        "# vis.plot_slice(study=study_grad)\n",
        "# vis.plot_param_importances(study=study_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade5ad12",
      "metadata": {
        "id": "ade5ad12"
      },
      "source": [
        "### 1.1. Giới thiệu Ridge - Sương Mai, Nhàn\n",
        "\n",
        "Although our main forecasting model is based on **LightGBM (a tree-based method)**, we still utilize several **linear algorithms** during the **feature selection phase** to identify the most influential weather variables.  \n",
        "These linear methods are implemented in the `feature_selection` module and used within functions such as `RFE`, `SequentialFeatureSelector`, and other embedded techniques.\n",
        "\n",
        "## Linear Models Applied\n",
        "\n",
        "### **1. Linear Regression**\n",
        "- Used as the **base estimator** in Recursive Feature Elimination (RFE) and Sequential Feature Selection (SFS).  \n",
        "- Helps determine which input features (e.g., humidity, pressure, temperature, wind speed) most strongly correlate with future targets.\n",
        "- Provides interpretable coefficients that indicate feature importance.\n",
        "\n",
        "### **2. Ridge Regression (L2 Regularization)**\n",
        "- Adds an **L2 penalty** to prevent overfitting and stabilize the feature importance when features are correlated.  \n",
        "- Commonly used for weather data where temperature, humidity, and pressure often show high multicollinearity.\n",
        "\n",
        "### **3. Lasso Regression (L1 Regularization)**\n",
        "- Encourages sparsity in coefficients — meaning it automatically performs **feature selection** by driving unimportant coefficients to zero.  \n",
        "- Helps reduce the dimensionality of the dataset and improve model interpretability.\n",
        "\n",
        "### **4. Elastic Net Regression**\n",
        "- Combines both L1 and L2 penalties to balance between Ridge’s stability and Lasso’s sparsity.  \n",
        "- Useful when many features are correlated and we still want automatic feature selection.\n",
        "\n",
        "## Why We Use Linear Models for Feature Selection\n",
        "\n",
        "- **Interpretability:** Linear coefficients directly indicate the relationship between each feature and the target variable.  \n",
        "- **Efficiency:** Linear models are lightweight and fast to train — ideal for running multiple feature selection rounds.  \n",
        "- **Stability:** Regularized variants (Ridge, Lasso, Elastic Net) reduce overfitting and improve reliability when selecting features for weather prediction.  \n",
        "\n",
        "These methods form the **foundation for our feature engineering pipeline**, allowing us to select only the most relevant variables before training more complex models such as **LightGBM** for multi-step forecasting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c24a315",
      "metadata": {
        "id": "0c24a315"
      },
      "source": [
        "- Đoạn linear này nói chung là Sương mai làm cho t bản tóm tắt kết quả lại, xong kết luận luôn là mình sẽ chọn tree base (LGB), còn bên dưới là quá trình chạy thử, tuning các thứ nếu thầy muốn xem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11661cdb",
      "metadata": {
        "id": "11661cdb"
      },
      "source": [
        "### 1.2. Input preparation (Feature Engineering and Selection) for linear model (Ridge)  - Sương Mai, Nhàn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because linear models (e.g., Ridge Regression) can only capture **linear relationships**, we designed a dedicated preprocessing pipeline to help them learn more complex patterns in the data.  \n",
        "This section describes how we engineered new interaction features, encoded categorical variables, scaled numeric ones, and removed redundant features before training the linear model.\n",
        "\n",
        "## Key Differences from LightGBM\n",
        "Unlike LightGBM, which can automatically model nonlinear relationships and handle categorical features internally, **linear models require explicit feature transformations and encodings**.  \n",
        "Therefore, several additional preprocessing steps are needed:\n",
        "- Manual creation of *interaction features* (to simulate nonlinear relationships).\n",
        "- Numeric encoding and scaling.\n",
        "- Removal of highly correlated or base features.\n",
        "\n",
        "\n",
        "### **Step 1 — Add Interaction Features**\n",
        "Since linear models can’t represent feature interactions automatically, we add them manually:\n",
        "\n",
        "```python\n",
        "df['wind_temp_index'] = df['windspeed'] * df['temp']\n",
        "df['pressure_temp_index'] = df['sealevelpressure'] * df['temp']\n",
        "df['humidity_cloud_index'] = (df['humidity'] * df['cloudcover']) / 100\n",
        "df['solar_temp_index'] = df['solarradiation'] * df['temp']\n",
        "df['temp_humidity_interaction'] = df['temp'] * df['humidity']\n",
        "df['wind_temp_interaction'] = df['winddir'] * df['temp']\n",
        "df['temp_dew_interaction'] = df['temp'] * df['dew']\n",
        "```\n",
        "\n",
        "These interaction terms allow the Ridge model to capture joint effects, such as how temperature × humidity or wind speed × temperature together influence weather.\n",
        "When `is_linear=True` is set in the feature engineering function, these interactions are automatically added."
      ],
      "metadata": {
        "id": "G2Bzes1DHp9E"
      },
      "id": "G2Bzes1DHp9E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2 — Encoding and Scaling**\n",
        "\n",
        "Linear models are sensitive to both feature type and scale, so all input data must be numeric and standardized.\n",
        "\n",
        "```python\n",
        "encoder = pl.build_encoding_pipeline(is_category=False)\n",
        "encoder.fit(X_train, X_train['temp'])\n",
        "X_train = encoder.transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "```\n",
        "***Explanation:***\n",
        "\n",
        "**Encoding:** Converts categorical columns (e.g., weather type) into numeric format using one-hot encoding or label encoding.\n",
        "\n",
        "**Scaling:** Uses StandardScaler by default to normalize numerical columns so that each has zero mean and unit variance.\n",
        "This ensures balanced weight updates and prevents large-valued features from dominating the model.\n",
        "\n",
        "We then confirm that no categorical data remains:\n",
        "\n",
        "```python\n",
        "cat_features = X_train.select_dtypes(include=['category', 'object']).columns\n",
        "print(\"Number of categorical features:\", len(cat_features))\n",
        "```"
      ],
      "metadata": {
        "id": "bipA4CfvJDyS"
      },
      "id": "bipA4CfvJDyS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3 — Drop Base Features**\n",
        "\n",
        "After encoding and generating new variables, we remove redundant or highly correlated features to avoid multicollinearity.\n",
        "\n",
        "```python\n",
        "print(\"\\nDrop Base:\")\n",
        "print(\"Shape before drop base:\", X_train.shape, X_test.shape)\n",
        "\n",
        "X_train = fe.drop_base_features(X_train)\n",
        "X_test = fe.drop_base_features(X_test)\n",
        "\n",
        "print(\"Shape after drop base:\", X_train.shape, X_test.shape)\n",
        "\n",
        "```\n",
        "***Purpose***\n",
        "\n",
        "**Drop Highly Correlated Features:** Removes columns that carry the same information.\n",
        "\n",
        "**Drop Base Features:** Removes original variables that have encoded or interaction counterparts.\n",
        "\n",
        "This step stabilizes coefficient estimation and prevents redundant predictors from inflating model variance.\n"
      ],
      "metadata": {
        "id": "KTuYR1dNJ6VR"
      },
      "id": "KTuYR1dNJ6VR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4 — Output Summary**\n",
        "\n",
        "After all preprocessing, the dataset for Ridge contains:\n",
        "\n",
        "```python\n",
        "Created 7 interaction features\n",
        "Created 78 lag features\n",
        "Created 84 rolling features\n",
        "Before Drop Base: (2893, 264) (697, 264)\n",
        "After Drop Base:  (2893, 243) (697, 243)\n",
        "```\n"
      ],
      "metadata": {
        "id": "YKFZdG4bIz_9"
      },
      "id": "YKFZdG4bIz_9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923009d9",
      "metadata": {
        "id": "923009d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b35bad-f7d4-42fe-98f9-de679903ab12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã tạo 7 biến interaction\n",
            "Đã tạo tổng cộng 78 lag features.\n",
            "Đã tạo 84 rolling features.\n",
            "Đã tạo 7 biến interaction\n",
            "Đã tạo tổng cộng 78 lag features.\n",
            "Đã tạo 84 rolling features.\n",
            "Train: ((2893, 264), (2893, 5)), Test: ((697, 264), (697, 5))\n",
            "\n",
            "Kiểm tra còn biến object hay category 0\n",
            "\n",
            "Drop Base\n",
            "số lượng Trước Khi drop base (2893, 264) (697, 264)\n",
            "số lượng sau drop base (2893, 243) (697, 243)\n"
          ]
        }
      ],
      "source": [
        "## lưu ý khi tune linear này sẽ khác so với LGB\n",
        "\n",
        "# 1. có sử dụng các biến interaction: is_linear = True\n",
        "\n",
        "# Tạo feature engineering (drop NaN sau khi rolling/lag)\n",
        "train_feat, target_col = fe.feature_engineering(train_processed, is_drop_nan= True, is_linear= True)\n",
        "test_feat, _ = fe.feature_engineering(test_processed, is_drop_nan= True, is_linear= True)\n",
        "\n",
        "# Chia X, y riêng biệt\n",
        "X_train = train_feat.drop(columns= target_col)\n",
        "y_train = train_feat[target_col]\n",
        "\n",
        "X_test = test_feat.drop(columns= target_col)\n",
        "y_test = test_feat[target_col]\n",
        "\n",
        "\n",
        "# 2. Encoding sang numeric\n",
        "encoder = pl.build_encoding_pipeline(is_category= False)\n",
        "encoder.fit(X_train, X_train['temp'])\n",
        "\n",
        "X_train = encoder.transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "\n",
        "print(f\"Train: {X_train.shape, y_train.shape}, Test: {X_test.shape, y_test.shape}\")\n",
        "\n",
        "cat_features = X_train.select_dtypes(include=['category','object']).columns\n",
        "print('\\nKiểm tra còn biến object hay category', len(cat_features))\n",
        "\n",
        "\n",
        "# 3. Drop base\n",
        "print('\\nDrop Base')\n",
        "print('số lượng Trước Khi drop base', X_train.shape, X_test.shape)\n",
        "X_train = fe.drop_base_features(X_train)\n",
        "X_test = fe.drop_base_features(X_test)\n",
        "print('số lượng sau drop base', X_train.shape, X_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f1248d",
      "metadata": {
        "id": "84f1248d"
      },
      "source": [
        "#### 1.3. Tuning trên cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30d71f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "e30d71f6",
        "outputId": "295118b6-85f1-4ef5-852c-4debf617cfc9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MissingConfigError",
          "evalue": "It seems ClearML is not configured on this machine!\nTo get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\nSetup instructions can be found here: https://clear.ml/docs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMissingConfigError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1424044336.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m task_lgbm = Task.init(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Temperature Forecasting\"\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# tên project trên ClearML (nếu chưa có sẽ tự tạo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtask_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ridge Optuna Tuning 1\"\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# tên task mới\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/task.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(cls, project_name, task_name, task_type, tags, reuse_last_task_id, continue_last_task, output_uri, auto_connect_arg_parser, auto_connect_frameworks, auto_resource_monitoring, auto_connect_streams, deferred_init)\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sub_process_task_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m                         task = cls._create_dev_task(\n\u001b[0m\u001b[1;32m    641\u001b[0m                             \u001b[0mdefault_project_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                             \u001b[0mdefault_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/task.py\u001b[0m in \u001b[0;36m_create_dev_task\u001b[0;34m(cls, default_project_name, default_task_name, default_task_type, tags, reuse_last_task_id, continue_last_task, detect_repo, auto_connect_streams)\u001b[0m\n\u001b[1;32m   4380\u001b[0m         \u001b[0;31m# create a new task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefault_task_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4382\u001b[0;31m             task = cls(\n\u001b[0m\u001b[1;32m   4383\u001b[0m                 \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__create_protection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4384\u001b[0m                 \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_project_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/task.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, private, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo_detect_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_interface/task/task.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, task_id, log, project_name, task_name, task_type, log_to_backend, raise_on_validation_errors, force_create)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mtask_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_task_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce_create\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__edit_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_interface/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, id, session, log, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIdObjectBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInterfaceBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIdObjectBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_interface/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, log, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInterfaceBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_interface/base.py\u001b[0m in \u001b[0;36m_get_default_session\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mInterfaceBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             InterfaceBase._default_session = Session(\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0minitialize_logging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_api/session/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, worker, api_key, secret_key, host, logger, verbose, config, http_retries_config, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/clearml/backend_api/session/session.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecret_key\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess_key\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__auth_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingConfigError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         super(Session, self).__init__(\n",
            "\u001b[0;31mMissingConfigError\u001b[0m: It seems ClearML is not configured on this machine!\nTo get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\nSetup instructions can be found here: https://clear.ml/docs"
          ]
        }
      ],
      "source": [
        "# Nhớ đổi tên task trong task_name\n",
        "\n",
        "if Task.current_task():\n",
        "    Task.current_task().close()\n",
        "\n",
        "task_lgbm = Task.init(\n",
        "    project_name=\"Temperature Forecasting\",         # tên project trên ClearML (nếu chưa có sẽ tự tạo)\n",
        "    task_name=\"Ridge Optuna Tuning 1\",            # tên task mới\n",
        "    task_type=Task.TaskTypes.optimizer            # loại task (training / testing / optimizer ...)\n",
        ")\n",
        "\n",
        "# print(\" Task created successfully!\")\n",
        "print(\"Task ID:\", task_lgbm.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb2d149",
      "metadata": {
        "id": "4fb2d149"
      },
      "outputs": [],
      "source": [
        "task_lgbm = Task.get_task(task_id=\"59847c902e2d4035b6d4bb584e1b3a78\")\n",
        "logger_lgbm = task_lgbm.get_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5650ba77",
      "metadata": {
        "id": "5650ba77"
      },
      "source": [
        "#### A. Chạy thử với các hyper parameter mặc định\n",
        "\n",
        "Pipeline mặc định sẽ gồm:\n",
        " - DropHighlyCorrelated1(threshold= 0.8) : Giải thích qua nó làm gì, tại sao cần\n",
        " - StandardScaler(): giải thích làm gì tạo sao cần\n",
        " - Ridge (alpha = 1.0, fit_intercapt = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43500a96",
      "metadata": {
        "id": "43500a96"
      },
      "outputs": [],
      "source": [
        "# === 1️ Cấu hình Ridge mặc định ===\n",
        "default_model_params = dict(\n",
        "    alpha=1.0,\n",
        "    fit_intercept=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === 2️ Cấu hình Feature Selection ===\n",
        "fs_params = dict(\n",
        "    corr_threshold=0.8,  # Cần tuning threshold\n",
        ")\n",
        "\n",
        "# === 3️ Pipeline gồm feature selection + scaler + Ridge ===\n",
        "ridge_pipeline = Pipeline([\n",
        "    (\"feature_selection\", fs.DropHighlyCorrelated1(threshold=fs_params['corr_threshold'])),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge(**default_model_params))\n",
        "])\n",
        "\n",
        "# === 4 Time Series Cross Validation ===\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "cv_scores = []\n",
        "cv_artifacts = {}\n",
        "\n",
        "print(\"=== Time Series Cross-Validation (Ridge + Scaling) ===\")\n",
        "\n",
        "fold_idx = 1\n",
        "for train_idx, val_idx in tscv.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Huấn luyện riêng cho từng target\n",
        "    y_pred_val_all = pd.DataFrame(index=y_val.index, columns=y_train.columns)\n",
        "    for target_col in y_train.columns:\n",
        "        model = ridge_pipeline\n",
        "        model.fit(X_tr, y_tr[target_col])\n",
        "        y_pred_val_all[target_col] = model.predict(X_val)\n",
        "\n",
        "    # Đánh giá\n",
        "    metrics_val = evaluate_multi_output(y_val, y_pred_val_all)\n",
        "    avg_val = metrics_val[\"average\"]\n",
        "    per_day_val = metrics_val[\"per_day\"]\n",
        "    cv_scores.append(avg_val)\n",
        "\n",
        "    print(f\"\\nFold {fold_idx} validation metrics:\")\n",
        "    print(avg_val)\n",
        "    print(per_day_val)\n",
        "\n",
        "    # Log artifact thay vì scalar\n",
        "    cv_artifacts[f\"Fold_{fold_idx}\"] = {\n",
        "        \"average\": avg_val,\n",
        "        \"per_day\": per_day_val\n",
        "    }\n",
        "\n",
        "    fold_idx += 1\n",
        "\n",
        "\n",
        "# === 5 Tổng hợp kết quả cross-validation ===\n",
        "cv_df = pd.DataFrame(cv_scores)\n",
        "cv_mean = cv_df.mean()\n",
        "cv_std = cv_df.std()\n",
        "\n",
        "print(\"\\n=====> Cross-validation trung bình:\")\n",
        "print(cv_mean)\n",
        "print(\"\\n=====> Cross-validation độ lệch chuẩn:\")\n",
        "print(cv_std)\n",
        "\n",
        "# Log artifact tổng hợp CV (mean + std)\n",
        "cv_artifacts[\"CV_Summary\"] = {\n",
        "    \"mean\": cv_mean.to_dict(),\n",
        "    \"std\": cv_std.to_dict()\n",
        "}\n",
        "\n",
        "# Gửi toàn bộ artifact CV lên ClearML\n",
        "task_lgbm.upload_artifact(\"Default_Ridge_CV_Detail\", cv_artifacts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d951ebc2",
      "metadata": {
        "id": "d951ebc2"
      },
      "source": [
        "### B. Tuning với Scaler, Drop Highly Correlated threshold, Model Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9c92d1",
      "metadata": {
        "id": "6a9c92d1"
      },
      "outputs": [],
      "source": [
        "## === A. Optuna Objective cho từng target RIÊNG BIỆT ==\n",
        "def objective_ridge_per_target(trial, target_name, target_idx):\n",
        "   # Chọn scaler\n",
        "   scaler_name = trial.suggest_categorical(\"scaler\", [\"standard\", \"minmax\", \"robust\"])\n",
        "   if scaler_name == \"standard\":\n",
        "      scaler = StandardScaler()\n",
        "   elif scaler_name == \"minmax\":\n",
        "      scaler = MinMaxScaler()\n",
        "   else:\n",
        "      scaler = RobustScaler()\n",
        "\n",
        "   # Hyperparameter cho Ridge\n",
        "   alpha = trial.suggest_categorical(\"alpha\", [0.001, 0.01, 0.1, 1.0, 10.0, 50.0, 100.0])\n",
        "   fit_intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
        "\n",
        "   # Hyperparameter cho Feature Selection - THÊM VÀO\n",
        "   corr_threshold = trial.suggest_float(\"corr_threshold\", 0.7, 0.95, step=0.05)\n",
        "\n",
        "   # TimeSeriesSplit\n",
        "   cv = TimeSeriesSplit(n_splits=5)\n",
        "   rmse_scores = []\n",
        "\n",
        "   for train_idx, val_idx in cv.split(X_train):\n",
        "      X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "      y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "      # Áp dụng feature selection cho từng fold - THÊM VÀO\n",
        "      high = fs.DropHighlyCorrelated1(threshold=corr_threshold)\n",
        "      X_tr_fs = high.fit_transform(X_tr)\n",
        "      X_val_fs = high.transform(X_val)\n",
        "\n",
        "      # Chỉ lấy target hiện tại\n",
        "      y_tr_single = y_tr.iloc[:, target_idx] if len(y_tr.shape) > 1 else y_tr\n",
        "      y_val_single = y_val.iloc[:, target_idx] if len(y_val.shape) > 1 else y_val\n",
        "\n",
        "      # Pipeline: scaler + Ridge (Single output)\n",
        "      ridge = Ridge(\n",
        "         alpha=alpha,\n",
        "         fit_intercept=fit_intercept,\n",
        "         random_state=42\n",
        "      )\n",
        "      pipeline = Pipeline([\n",
        "         (\"scaler\", scaler),\n",
        "         (\"model\", ridge)\n",
        "      ])\n",
        "\n",
        "      pipeline.fit(X_tr_fs, y_tr_single)\n",
        "      y_pred_val = pipeline.predict(X_val_fs)\n",
        "\n",
        "      # Tính RMSE cho target hiện tại\n",
        "      result = evaluate(y_val_single, y_pred_val)\n",
        "      rmse = result['RMSE']\n",
        "      rmse_scores.append(rmse)\n",
        "\n",
        "   mean_rmse = np.mean(rmse_scores)\n",
        "\n",
        "   # Log lên ClearML với series theo target\n",
        "   logger_lgbm.report_scalar(\n",
        "      title=f'Optuna Tuning - Ridge [{target_name}]',\n",
        "      series='Trial RMSE',\n",
        "      value=mean_rmse,\n",
        "      iteration=trial.number\n",
        "   )\n",
        "\n",
        "   params_table = pd.DataFrame([{\n",
        "      \"target\": target_name,\n",
        "      \"scaler\": scaler_name,\n",
        "      \"alpha\": alpha,\n",
        "      \"fit_intercept\": fit_intercept,\n",
        "      \"corr_threshold\": corr_threshold,\n",
        "   }])\n",
        "\n",
        "   logger_lgbm.report_table(\n",
        "      title=f\"Trial {trial.number} - {target_name}\",\n",
        "      series=\"params\",\n",
        "      iteration=trial.number,\n",
        "      table_plot=params_table\n",
        "   )\n",
        "\n",
        "   return mean_rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bfc3731",
      "metadata": {
        "id": "9bfc3731"
      },
      "outputs": [],
      "source": [
        "## === B. Hàm helper ===\n",
        "def get_scaler_from_params(scaler_name):\n",
        "   if scaler_name == \"standard\":\n",
        "      return StandardScaler()\n",
        "   elif scaler_name == \"minmax\":\n",
        "      return MinMaxScaler()\n",
        "   else:\n",
        "      return RobustScaler()\n",
        "\n",
        "def extract_ridge_params(params):\n",
        "   return {\n",
        "      'alpha': params['alpha'],\n",
        "      'fit_intercept': params['fit_intercept'],\n",
        "      'random_state': 42\n",
        "   }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cda1294",
      "metadata": {
        "id": "5cda1294"
      },
      "outputs": [],
      "source": [
        "\n",
        "## === C.. Tune riêng cho từng target ===\n",
        "best_models_per_target = {}\n",
        "best_params_per_target = {}\n",
        "feature_selectors_per_target = {}\n",
        "\n",
        "\n",
        "# Tắt logging Nó hiện nhiều quá thì bỏ comment dòng này ra, đằng nào cũng quan sát được trên clearml\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "\n",
        "for idx, target_name in enumerate(y_train.columns):\n",
        "   print(f\"Tuning Ridge for target: {target_name} ({idx + 1}/{len(y_train.columns)})\")\n",
        "\n",
        "   # Tạo study riêng cho mỗi target\n",
        "   study = optuna.create_study(\n",
        "      direction='minimize',\n",
        "      sampler=optuna.samplers.TPESampler(seed=42)\n",
        "   )\n",
        "\n",
        "   # Gọi Study Optimize\n",
        "   study.optimize(\n",
        "      lambda trial: objective_ridge_per_target(trial, target_name, idx),\n",
        "      n_trials=100,\n",
        "      show_progress_bar=False\n",
        "   )\n",
        "\n",
        "   # Lưu best params và model cho target này\n",
        "   best_params_per_target[target_name] = study.best_trial.params\n",
        "   best_params_per_target[target_name]['target_idx'] = idx\n",
        "\n",
        "   # Fit best model cho target này với feature selection\n",
        "   best_scaler = get_scaler_from_params(study.best_trial.params[\"scaler\"])\n",
        "   best_ridge = Ridge(**extract_ridge_params(study.best_trial.params))\n",
        "\n",
        "   # Áp dụng feature selection trên toàn bộ training data\n",
        "   high = fs.DropHighlyCorrelated1(threshold=study.best_trial.params[\"corr_threshold\"])\n",
        "   X_train_fs = high.fit_transform(X_train)\n",
        "\n",
        "   # Lưu feature selectors để sử dụng sau\n",
        "   feature_selectors_per_target[target_name] = {\n",
        "      'correlation_selector': high,\n",
        "   }\n",
        "\n",
        "   best_pipeline = Pipeline([\n",
        "      (\"scaler\", best_scaler),\n",
        "      (\"model\", best_ridge)\n",
        "   ])\n",
        "\n",
        "   # Train trên toàn bộ data đã được feature selection\n",
        "   y_target = y_train.iloc[:, idx] if len(y_train.shape) > 1 else y_train\n",
        "   best_pipeline.fit(X_train_fs, y_target)\n",
        "   best_models_per_target[target_name] = best_pipeline\n",
        "\n",
        "   # Log kết quả từng target lên ClearML\n",
        "   logger_lgbm.report_scalar(\n",
        "      title='Best RMSE per Target',\n",
        "      series=target_name,\n",
        "      value=study.best_value,\n",
        "      iteration=idx\n",
        "   )\n",
        "\n",
        "   print(f\" {target_name} - Best RMSE: {study.best_value:.4f}\")\n",
        "   print(f\" {target_name} - Final features: {X_train_fs.shape[1]}\")\n",
        "\n",
        "# Khôi phục logging\n",
        "#optuna.logging.set_verbosity(optuna.logging.INFO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d2a84a",
      "metadata": {
        "id": "02d2a84a"
      },
      "source": [
        "### C. Training final model với bộ hyper paramter và đánh giá cuối cùng trên Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dcd372",
      "metadata": {
        "id": "58dcd372"
      },
      "outputs": [],
      "source": [
        "## === D. Tạo MultiOutput wrapper từ các model riêng ===\n",
        "class CustomMultiOutputRegressor:\n",
        "   def __init__(self, models_per_target, feature_selectors_per_target):\n",
        "      self.models_per_target = models_per_target\n",
        "      self.feature_selectors_per_target = feature_selectors_per_target\n",
        "      self.target_names = list(models_per_target.keys())\n",
        "\n",
        "   def predict(self, X):\n",
        "      predictions = []\n",
        "      for target_name, model in self.models_per_target.items():\n",
        "         # Áp dụng feature selection tương ứng cho từng target\n",
        "         selectors = self.feature_selectors_per_target[target_name]\n",
        "         X_fs = selectors['correlation_selector'].transform(X)\n",
        "\n",
        "         pred = model.predict(X_fs).reshape(-1, 1)\n",
        "         predictions.append(pred)\n",
        "      return np.hstack(predictions)\n",
        "\n",
        "   def get_params(self, deep=True):\n",
        "      return {\n",
        "         \"models_per_target\": self.models_per_target,\n",
        "         \"feature_selectors_per_target\": self.feature_selectors_per_target\n",
        "      }\n",
        "\n",
        "# Tạo final model với feature selectors\n",
        "final_multi_model = CustomMultiOutputRegressor(best_models_per_target, feature_selectors_per_target)\n",
        "\n",
        "## === E. Đánh giá final model ===\n",
        "y_pred_test = final_multi_model.predict(X_test)\n",
        "y_pred_train = final_multi_model.predict(X_train)\n",
        "\n",
        "final_test_metrics = evaluate_multi_output(y_test, y_pred_test)\n",
        "final_train_metrics = evaluate_multi_output(y_train, y_pred_train)\n",
        "\n",
        "print(\"Final Model - Test metrics (average):\", final_test_metrics[\"average\"])\n",
        "print(\"Final Model - Test metrics (perday):\", final_test_metrics[\"per_day\"])\n",
        "print()\n",
        "print(\"Final Model - Train metrics (average):\", final_train_metrics[\"average\"])\n",
        "print(\"Final Model - Train metrics (perday):\", final_train_metrics[\"per_day\"])\n",
        "\n",
        "# Log final results\n",
        "task_lgbm.upload_artifact(\"Best Parameters Per Target\", best_params_per_target)\n",
        "task_lgbm.upload_artifact(\"Feature Selectors Per Target\", feature_selectors_per_target)\n",
        "task_lgbm.upload_artifact(\"Final Model - Test Metrics\", final_test_metrics)\n",
        "task_lgbm.upload_artifact(\"Final Model - Train Metrics\", final_train_metrics)\n",
        "\n",
        "## === F. Lưu tất cả models ===\n",
        "ridge_models_path = r\"models/Ridge_models_per_target.pkl\"\n",
        "joblib.dump({\n",
        "   'models': best_models_per_target,\n",
        "   'params': best_params_per_target,\n",
        "   'feature_selectors': feature_selectors_per_target,\n",
        "   'final_model': final_multi_model\n",
        "}, ridge_models_path)\n",
        "\n",
        "print('\\n')\n",
        "print(\"=== FEATURE SELECTION SUMMARY ===\")\n",
        "for target_name in y_train.columns:\n",
        "    selectors = feature_selectors_per_target[target_name]\n",
        "    original_features = X_train.shape[1]\n",
        "\n",
        "    # Chỉ còn correlation_selector, không còn feature_selector nữa\n",
        "    correlation_selector = selectors['correlation_selector']\n",
        "\n",
        "    # Tính số features sau khi drop correlated\n",
        "    features_after_corr = original_features - len(correlation_selector.to_drop_)\n",
        "\n",
        "    print(f\"{target_name}: {original_features} → {features_after_corr} features\")\n",
        "    print(f\"  - Dropped {len(correlation_selector.to_drop_)} highly correlated features\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0038d83f",
      "metadata": {
        "id": "0038d83f"
      },
      "source": [
        "### Thêm link log kết quả tổng hợp của ClearML vào đây, kèm mấy cái ảnh biểu đồ tuning qua các trial, giải thích quá trình tune (mấy cái biểu đồ đậm nhạt, các thứ ấy để thầy biết là  mình có tune tử tế tinh chỉnh hyper các kiểu cho nó hiệu quả hơn) - Nhàn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0a9a8c",
      "metadata": {
        "id": "cb0a9a8c"
      },
      "source": [
        "### 2. LGB Model (Our Final Model) - Sương Mai, Hoàng\n",
        "- Viết giải thích ngắn, tại sao chọn Model điểm ưu việt của nó, ... có nhiều bài trên mạng nó nói geekforgeek, ... lên đấy cop rồi tự điều chỉnh lại\n",
        "\n",
        "- Các phần so sánh thì chưa cần tune, bao giờ so sánh xong, chọn được option tốt nhất thì mình sẽ tune cái option tốt nhất đấy nhé"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1ed18f",
      "metadata": {
        "id": "ce1ed18f"
      },
      "source": [
        "### 2.1. Data preparation for LGB\n",
        "- Sẽ loại bỏ những biến interaction (giải thích vì sao, vdu như do tree tự học được): is_linear = False (Khi chạy thử thì có thêm vào kết quả tệ đi thật)\n",
        "- Các biến category có 2 lựa chọn là để nguyên hoặc encoding\n",
        "- Drop các base feature\n",
        "\n",
        "    base = ['tempmax', 'tempmin', 'temp', 'feelslikemax', 'feelslikemin',\n",
        "       'feelslike', 'dew', 'humidity', 'precip', 'precipprob', 'precipcover',\n",
        "       'preciptype', 'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir',\n",
        "       'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation',\n",
        "       'solarenergy', 'uvindex', 'severerisk', 'moonphase']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03c84ce",
      "metadata": {
        "id": "e03c84ce"
      },
      "outputs": [],
      "source": [
        "# 1. Không sử dụng các biến interaction: is_linear = False\n",
        "\n",
        "# Tạo feature engineering (drop NaN sau khi rolling/lag)\n",
        "train_feat, target_col = fe.feature_engineering(train_processed, is_drop_nan= True, is_linear= False) # không tạo biến interaction\n",
        "test_feat, _ = fe.feature_engineering(test_processed, is_drop_nan= True, is_linear= False)\n",
        "\n",
        "# Chia X, y riêng biệt\n",
        "X_train = train_feat.drop(columns= target_col)\n",
        "y_train = train_feat[target_col]\n",
        "\n",
        "X_test = test_feat.drop(columns= target_col)\n",
        "y_test = test_feat[target_col]\n",
        "\n",
        "# 2. Drop base - Chỉ sử dụng derive feature\n",
        "print('\\nDrop Base')\n",
        "print('số lượng Trước Khi drop base', X_train.shape, X_test.shape)\n",
        "X_train = fe.drop_base_features(X_train)\n",
        "X_test = fe.drop_base_features(X_test)\n",
        "print('số lượng sau drop base', X_train.shape, X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8347e7f",
      "metadata": {
        "id": "b8347e7f"
      },
      "source": [
        "### 2.2. Category Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e40d7ec5",
      "metadata": {
        "id": "e40d7ec5"
      },
      "source": [
        "#### A. Các biến category trong Input của mình - Sương Mai\n",
        "\n",
        "- Ngoài 'conditions' có sẵn,  thêm 2 category nữa là 'wind_category' và 'season'\n",
        "- Pipeline sử dụng để encode `pl.build_encoding_pipeline(is_category= True)` trong file `pipeline.py`\n",
        "      ![image.png](attachment:image.png)\n",
        "\n",
        "- Thêm bảng giải thích ngắn gọn 3 kiểu encoding: target encoding, ordinal encoding, quantile\n",
        "- (Có thể tạo bảng, nêu ngắn gọn mỗi biến có các unique value nào, ... thấy gì phù hợp thì thêm vào)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f4d9478",
      "metadata": {
        "id": "4f4d9478"
      },
      "outputs": [],
      "source": [
        "# 3. Kiểm tra các biến Category\n",
        "encoder = pl.build_encoding_pipeline(is_category=True)\n",
        "encoder.fit(X_train, train_feat['temp'])\n",
        "\n",
        "X_train = encoder.transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "# Kích thước dữ liệu\n",
        "print(\"=\" * 60)\n",
        "print(f\" Kích thước dữ liệu:\")\n",
        "print(f\"   - Train: {X_train.shape} | Target: {y_train.shape}\")\n",
        "print(f\"   - Test : {X_test.shape} | Target: {y_test.shape}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "cat_features = X_train.select_dtypes(include=['category']).columns\n",
        "\n",
        "print(\"\\nThông tin chi tiết các feature categorical:\")\n",
        "for col in cat_features:\n",
        "    unique_vals = list(X_train[col].unique())\n",
        "    print(f\"• {col} ({len(unique_vals)} lớp): {unique_vals}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0fa846",
      "metadata": {
        "id": "fc0fa846"
      },
      "source": [
        "### B. Nói ngắn gọn cách/ thuật toán LGB xử lí Category - Sương Mai\n",
        "Sử dụng thuật toán gì, ....\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76580a7",
      "metadata": {
        "id": "b76580a7"
      },
      "source": [
        "### 2.3. Tuning and Training LGB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89415c8",
      "metadata": {
        "id": "b89415c8"
      },
      "source": [
        "### A. Giải thích các hyper paramter mình tune - Sương Mai, Hoàng đọc tìm hiểu luôn\n",
        "vd:\n",
        "\n",
        "Trong cái boosting type (check lại kiến thức t vt nhé ko đảm bảo)\n",
        "<br> goss: lựa chọn ngẫu nhiên dựa theo độ lớn gradient, tập trung vào các point có grad lớn - thì không dùng được subsample và subsample_fraction\n",
        "<br> gbdt, dart: lựa chọn ngẫu nhiên dựa vào bagging (chọn ngẫu nhiên qua tỉ lệ subsample và subsample_fraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8ef6bb",
      "metadata": {
        "id": "fc8ef6bb"
      },
      "source": [
        "### B. Sử dụng hyper parameter mặc định của model và sử dụng category feature chưa encoding sang numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c20978",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "61c20978",
        "outputId": "2d4f3930-0ec3-4f86-9d19-1fcfa73d54a4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Task' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1144279217.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Đổi tên task trong task_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m task_lgbm = Task.init(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Task' is not defined"
          ]
        }
      ],
      "source": [
        "# Đổi tên task trong task_name\n",
        "if Task.current_task():\n",
        "    Task.current_task().close()\n",
        "\n",
        "task_lgbm = Task.init(\n",
        "    project_name=\"Temperature Forecasting\",         # tên project trên ClearML (nếu chưa có sẽ tự tạo)\n",
        "    task_name=\"LGB Optuna Tuning 1\",            # tên task mới\n",
        "    task_type=Task.TaskTypes.optimizer            # loại task (training / testing / optimizer ...)\n",
        ")\n",
        "\n",
        "# print(\" Task created successfully!\")\n",
        "print(\"Task ID:\", task_lgbm.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f2cda7",
      "metadata": {
        "id": "59f2cda7"
      },
      "outputs": [],
      "source": [
        "task_lgbm = Task.get_task(task_id=\"648bdd16f71f4f80a010f6ae7ec29ba1\")\n",
        "logger_lgbm = task_lgbm.get_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bd6e35",
      "metadata": {
        "id": "24bd6e35"
      },
      "outputs": [],
      "source": [
        "# === 1️. Cấu hình LGBM mặc định ===\n",
        "default_lgbm_params = dict(\n",
        "    boosting_type='gbdt',\n",
        "    objective='regression',\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=-1,  # -1 means no limit\n",
        "    num_leaves=31,\n",
        "    min_child_samples=20,\n",
        "    subsample=1.0,\n",
        "    colsample_bytree=1.0,\n",
        "    reg_alpha=0.0,\n",
        "    reg_lambda=0.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# ===2. Pipeline chỉ gồm encoding + LGBM ===\n",
        "lgbm_pipeline = Pipeline([\n",
        "    (\"encoding\", pl.build_encoding_pipeline(\n",
        "        is_category=False,\n",
        "        encoding_method_condition='target',\n",
        "        n_seasons=5,\n",
        "        n_quantiles=4\n",
        "    )),\n",
        "    (\"lgbm\", LGBMRegressor(**default_lgbm_params))\n",
        "])\n",
        "\n",
        "# === 3. Time Series Cross Validation ===\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "cv_scores = []\n",
        "cv_artifacts = {}\n",
        "\n",
        "print(\"=== Time Series Cross-Validation (LGBM + Encoding) ===\")\n",
        "\n",
        "fold_idx = 1\n",
        "for train_idx, val_idx in tscv.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Huấn luyện riêng cho từng target\n",
        "    y_pred_val_all = pd.DataFrame(index=y_val.index, columns=y_train.columns)\n",
        "\n",
        "    # Theo dõi số lượng features\n",
        "    feature_counts = {}\n",
        "\n",
        "    for target_col in y_train.columns:\n",
        "        # Clone pipeline để tránh ảnh hưởng giữa các target\n",
        "        model = clone(lgbm_pipeline)\n",
        "\n",
        "        # Fit model\n",
        "        model.fit(X_tr, y_tr[target_col])\n",
        "        y_pred_val_all[target_col] = model.predict(X_val)\n",
        "\n",
        "        # Lấy thông tin encoding\n",
        "        X_encoded = model.named_steps['encoding'].transform(X_tr.head(1))\n",
        "        feature_counts[target_col] = {\n",
        "            'original_features': X_tr.shape[1],\n",
        "            'final_features': X_encoded.shape[1]\n",
        "        }\n",
        "\n",
        "    # Đánh giá\n",
        "    metrics_val = evaluate_multi_output(y_val, y_pred_val_all)\n",
        "    avg_val = metrics_val[\"average\"]\n",
        "    per_day_val = metrics_val[\"per_day\"]\n",
        "    cv_scores.append(avg_val)\n",
        "\n",
        "    print()\n",
        "    print(\"Metrics:\")\n",
        "    print(avg_val)\n",
        "    print(\"Per day metrics:\")\n",
        "    print(per_day_val)\n",
        "    print()\n",
        "\n",
        "    # Log artifact\n",
        "    cv_artifacts[f\"Fold_{fold_idx}\"] = {\n",
        "        \"average\": avg_val,\n",
        "        \"per_day\": per_day_val,\n",
        "        \"feature_counts\": feature_counts\n",
        "    }\n",
        "\n",
        "    fold_idx += 1\n",
        "\n",
        "# === 4. Tổng hợp kết quả cross-validation ===\n",
        "cv_df = pd.DataFrame(cv_scores)\n",
        "cv_mean = cv_df.mean()\n",
        "cv_std = cv_df.std()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=====> Cross-validation trung bình:\")\n",
        "print(cv_mean)\n",
        "print(\"\\n=====> Cross-validation độ lệch chuẩn:\")\n",
        "print(cv_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865cf620",
      "metadata": {
        "id": "865cf620"
      },
      "outputs": [],
      "source": [
        "# Log artifact tổng hợp CV (mean + std)\n",
        "cv_artifacts[\"CV_Summary\"] = {\n",
        "    \"mean\": cv_mean.to_dict(),\n",
        "    \"std\": cv_std.to_dict(),\n",
        "    \"model_params\": default_lgbm_params,\n",
        "    \"encoding_params\": {\n",
        "        \"is_category\": False,\n",
        "        \"encoding_method_condition\": \"target\",\n",
        "        \"n_seasons\": 5,\n",
        "        \"n_quantiles\": 4\n",
        "    }\n",
        "}\n",
        "\n",
        "# Gửi toàn bộ artifact CV lên ClearML\n",
        "task_lgbm.upload_artifact(\"Default_LGBM_CV_Detail\", cv_artifacts)\n",
        "\n",
        "print(\"\\n=== DEFAULT LGBM MODEL CONFIGURATION ===\")\n",
        "print(f\"Boosting type: {default_lgbm_params['boosting_type']}\")\n",
        "print(f\"Learning rate: {default_lgbm_params['learning_rate']}\")\n",
        "print(f\"Number of estimators: {default_lgbm_params['n_estimators']}\")\n",
        "print(f\"Max depth: {default_lgbm_params['max_depth']}\")\n",
        "print(f\"Number of leaves: {default_lgbm_params['num_leaves']}\")\n",
        "print(f\"Encoding method: target\")\n",
        "print(f\"Number of seasons: 5\")\n",
        "print(f\"Number of quantiles: 4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1260c3da",
      "metadata": {
        "id": "1260c3da"
      },
      "source": [
        "### B. Tuning Các lựa chọn encoding + Model LGB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a04699c3",
      "metadata": {
        "id": "a04699c3"
      },
      "source": [
        "chạy lâu quá, nên t chạy thử đén trial 35 của temp next 1 thôi, c xem cách nào cải thiện ko thì chịu khó :'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19a2dcf",
      "metadata": {
        "id": "c19a2dcf"
      },
      "outputs": [],
      "source": [
        "# === 1. Objective function cho LGBM ===\n",
        "def objective_lgbm_per_target(trial, target_name, target_idx):\n",
        "    # Hyperparameters cho encoding pipeline\n",
        "    encoding_method_condition = trial.suggest_categorical(\"encoding_method_condition\",\n",
        "                                                         [\"ordinal\", \"target\", \"quantile\"])\n",
        "    n_seasons = trial.suggest_int(\"n_seasons\", 3, 8)\n",
        "    n_quantiles = trial.suggest_int(\"n_quantiles\", 2, 6)\n",
        "\n",
        "    # Tune is_category cho từng encoder\n",
        "    conditions_is_category = trial.suggest_categorical(\"conditions_is_category\", [True, False])\n",
        "    season_is_category = trial.suggest_categorical(\"season_is_category\", [True, False])\n",
        "    wind_is_category = trial.suggest_categorical(\"wind_is_category\", [True, False])\n",
        "\n",
        "    # Hyperparameters cho LGBM\n",
        "    boosting_type = trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"dart\", \"goss\"])\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True)\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 12)\n",
        "    num_leaves = trial.suggest_int(\"num_leaves\", 15, 255)\n",
        "    min_child_samples = trial.suggest_int(\"min_child_samples\", 5, 100)\n",
        "    min_split_gain = trial.suggest_float(\"min_split_gain\", 0.0, 1.0)\n",
        "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
        "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True)\n",
        "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True)\n",
        "\n",
        "    # Conditional parameters\n",
        "    if boosting_type in ['goss', 'dart']:\n",
        "        subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
        "    else:\n",
        "        subsample = 1.0\n",
        "\n",
        "    if boosting_type == 'dart':\n",
        "        subsample_freq = trial.suggest_int(\"subsample_freq\", 1, 10)\n",
        "    else:\n",
        "        subsample_freq = 0\n",
        "\n",
        "    # TimeSeriesSplit\n",
        "    cv = TimeSeriesSplit(n_splits=5)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        # Chỉ lấy target hiện tại\n",
        "        y_tr_single = y_tr.iloc[:, target_idx] if len(y_tr.shape) > 1 else y_tr\n",
        "        y_val_single = y_val.iloc[:, target_idx] if len(y_val.shape) > 1 else y_val\n",
        "\n",
        "        try:\n",
        "            # Build encoding pipeline với các parameters được tuning\n",
        "            encoding_pipeline = pl.build_encoding_pipeline(\n",
        "                is_category=conditions_is_category,\n",
        "                encoding_method_condition=encoding_method_condition,\n",
        "                n_seasons=n_seasons,\n",
        "                n_quantiles=n_quantiles\n",
        "            )\n",
        "\n",
        "            # Override is_category cho từng component\n",
        "            encoding_pipeline.named_steps['season_encode'].is_category = season_is_category\n",
        "            encoding_pipeline.named_steps['wind_encode'].is_category = wind_is_category\n",
        "\n",
        "            # Apply encoding\n",
        "            X_tr_encoded = encoding_pipeline.fit_transform(X_tr, y_tr_single)\n",
        "            X_val_encoded = encoding_pipeline.transform(X_val)\n",
        "\n",
        "            # LGBM model - KHÔNG dùng early stopping trong CV\n",
        "            lgbm = LGBMRegressor(\n",
        "                boosting_type=boosting_type,\n",
        "                objective='regression',\n",
        "                learning_rate=learning_rate,\n",
        "                n_estimators=n_estimators,\n",
        "                max_depth=max_depth,\n",
        "                num_leaves=num_leaves,\n",
        "                min_child_samples=min_child_samples,\n",
        "                min_split_gain=min_split_gain,\n",
        "                colsample_bytree=colsample_bytree,\n",
        "                reg_alpha=reg_alpha,\n",
        "                reg_lambda=reg_lambda,\n",
        "                subsample=subsample,\n",
        "                subsample_freq=subsample_freq,\n",
        "                random_state=42,\n",
        "                n_jobs= 1,\n",
        "                verbosity=-1\n",
        "            )\n",
        "\n",
        "            # SỬA LẠI: Fit đơn giản không dùng early stopping trong CV\n",
        "            lgbm.fit(X_tr_encoded, y_tr_single)\n",
        "\n",
        "            y_pred_val = lgbm.predict(X_val_encoded)\n",
        "            result = evaluate(y_val_single, y_pred_val)\n",
        "            rmse = result['RMSE']\n",
        "            rmse_scores.append(rmse)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in trial: {e}\")\n",
        "            return float('inf')\n",
        "\n",
        "    mean_rmse = np.mean(rmse_scores)\n",
        "\n",
        "    # Log lên ClearML\n",
        "    logger_lgbm.report_scalar(\n",
        "        title=f'Optuna Tuning - LGBM [{target_name}]',\n",
        "        series='Trial RMSE',\n",
        "        value=mean_rmse,\n",
        "        iteration=trial.number\n",
        "    )\n",
        "\n",
        "    params_table = pd.DataFrame([{\n",
        "        \"target\": target_name,\n",
        "        \"boosting_type\": boosting_type,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"n_estimators\": n_estimators,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"num_leaves\": num_leaves,\n",
        "        \"encoding_method\": encoding_method_condition,\n",
        "        \"n_seasons\": n_seasons,\n",
        "        \"n_quantiles\": n_quantiles\n",
        "    }])\n",
        "    logger_lgbm.report_table(\n",
        "        title=f\"Trial {trial.number} - {target_name}\",\n",
        "        series=\"params\",\n",
        "        iteration=trial.number,\n",
        "        table_plot=params_table\n",
        "    )\n",
        "\n",
        "    return mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56069b0e",
      "metadata": {
        "id": "56069b0e"
      },
      "outputs": [],
      "source": [
        "# === 2. Hàm helper cho LGBM ===\n",
        "def extract_lgbm_params(params):\n",
        "    lgbm_params = {\n",
        "        'boosting_type': params['boosting_type'],\n",
        "        'objective': 'regression',\n",
        "        'learning_rate': params['learning_rate'],\n",
        "        'n_estimators': params['n_estimators'],\n",
        "        'max_depth': params['max_depth'],\n",
        "        'num_leaves': params['num_leaves'],\n",
        "        'min_child_samples': params['min_child_samples'],\n",
        "        'min_split_gain': params['min_split_gain'],\n",
        "        'colsample_bytree': params['colsample_bytree'],\n",
        "        'reg_alpha': params['reg_alpha'],\n",
        "        'reg_lambda': params['reg_lambda'],\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    # Conditional parameters\n",
        "    if params['boosting_type'] in ['goss', 'dart']:\n",
        "        lgbm_params['subsample'] = params['subsample']\n",
        "\n",
        "    if params['boosting_type'] == 'dart':\n",
        "        lgbm_params['subsample_freq'] = params['subsample_freq']\n",
        "\n",
        "    return lgbm_params\n",
        "\n",
        "def build_final_encoding_pipeline(params):\n",
        "    \"\"\"Build encoding pipeline với best parameters\"\"\"\n",
        "    return pl.build_encoding_pipeline(\n",
        "        is_category=params['conditions_is_category'],\n",
        "        encoding_method_condition=params['encoding_method_condition'],\n",
        "        n_seasons=params['n_seasons'],\n",
        "        n_quantiles=params['n_quantiles']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1e14d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2c1e14d6",
        "outputId": "3bc933b8-6abe-49bd-9899-c6f1ae05b4ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4061586184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# optuna.logging.set_verbosity(optuna.logging.WARNING)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tuning LGBM for target: {target_name} ({idx + 1}/{len(y_train.columns)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "source": [
        "# === 3. Tune riêng cho từng target ===\n",
        "best_lgbm_models_per_target = {}\n",
        "best_lgbm_params_per_target = {}\n",
        "encoding_pipelines_per_target = {}\n",
        "\n",
        "# Tắt logging\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "for idx, target_name in enumerate(y_train.columns):\n",
        "    print(f\"Tuning LGBM for target: {target_name} ({idx + 1}/{len(y_train.columns)})\")\n",
        "\n",
        "    # Tạo study riêng cho mỗi target\n",
        "    study = optuna.create_study(\n",
        "        direction='minimize',\n",
        "        sampler=optuna.samplers.TPESampler(seed=42)\n",
        "    )\n",
        "\n",
        "    study.optimize(\n",
        "        lambda trial: objective_lgbm_per_target(trial, target_name, idx),\n",
        "        n_trials= 50,\n",
        "        show_progress_bar=False,\n",
        "        callbacks=[lambda study, trial: None]\n",
        "    )\n",
        "\n",
        "    # Lưu best params\n",
        "    best_lgbm_params_per_target[target_name] = study.best_trial.params\n",
        "    best_lgbm_params_per_target[target_name]['target_idx'] = idx\n",
        "\n",
        "    # Build final encoding pipeline\n",
        "    encoding_pipeline = build_final_encoding_pipeline(study.best_trial.params)\n",
        "\n",
        "    # Override is_category cho từng component\n",
        "    encoding_pipeline.named_steps['season_encode'].is_category = study.best_trial.params['season_is_category']\n",
        "    encoding_pipeline.named_steps['wind_encode'].is_category = study.best_trial.params['wind_is_category']\n",
        "\n",
        "    # encoding trên toàn bộ training data\n",
        "    X_train_encoded = encoding_pipeline.fit_transform(\n",
        "        X_train,\n",
        "        y_train.iloc[:, idx] if len(y_train.shape) > 1 else y_train\n",
        "    )\n",
        "\n",
        "    #  train final LGBM model\n",
        "    best_lgbm = LGBMRegressor(**extract_lgbm_params(study.best_trial.params))\n",
        "\n",
        "    best_lgbm.fit(\n",
        "        X_train_encoded,\n",
        "        y_train.iloc[:, idx] if len(y_train.shape) > 1 else y_train\n",
        "    )\n",
        "\n",
        "    best_lgbm_models_per_target[target_name] = {\n",
        "        'model': best_lgbm,\n",
        "        'encoding_pipeline': encoding_pipeline\n",
        "    }\n",
        "\n",
        "    encoding_pipelines_per_target[target_name] = encoding_pipeline\n",
        "\n",
        "    # Log kết quả\n",
        "    logger_lgbm.report_scalar(\n",
        "        title='Best RMSE per Target - LGBM',\n",
        "        series=target_name,\n",
        "        value=study.best_value,\n",
        "        iteration=idx\n",
        "    )\n",
        "\n",
        "    print(f\" {target_name} - Best RMSE: {study.best_value:.4f}\")\n",
        "    print(f\" {target_name} - Best boosting: {study.best_trial.params['boosting_type']}\")\n",
        "    print(f\" {target_name} - Encoding: {study.best_trial.params['encoding_method_condition']}\")\n",
        "    print(f\" {target_name} - Seasons: {study.best_trial.params['n_seasons']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# Khôi phục logging\n",
        "#optuna.logging.set_verbosity(optuna.logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9a1786",
      "metadata": {
        "id": "3d9a1786"
      },
      "source": [
        "### Đoạn bên dưới có early stopping với prune cơ mà nó có lỗi error in trial gì đó, Hoàng check hoặc thay code mới của c cg dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62727bc8",
      "metadata": {
        "id": "62727bc8"
      },
      "outputs": [],
      "source": [
        "from optuna.pruners import MedianPruner\n",
        "from lightgbm import early_stopping\n",
        "\n",
        "# === 1. Objective function cho LGBM với Early Stopping và Pruner ===\n",
        "def objective_lgbm_per_target(trial, target_name, target_idx):\n",
        "    # Hyperparameters cho encoding pipeline\n",
        "    encoding_method_condition = trial.suggest_categorical(\"encoding_method_condition\",\n",
        "                                                         [\"ordinal\", \"target\", \"quantile\"])\n",
        "    n_seasons = trial.suggest_int(\"n_seasons\", 3, 8)\n",
        "    n_quantiles = trial.suggest_int(\"n_quantiles\", 2, 6)\n",
        "\n",
        "    # Tune is_category cho từng encoder\n",
        "    conditions_is_category = trial.suggest_categorical(\"conditions_is_category\", [True, False])\n",
        "    season_is_category = trial.suggest_categorical(\"season_is_category\", [True, False])\n",
        "    wind_is_category = trial.suggest_categorical(\"wind_is_category\", [True, False])\n",
        "\n",
        "    # Hyperparameters cho LGBM\n",
        "    boosting_type = trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"dart\", \"goss\"])\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True)\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 12)\n",
        "    num_leaves = trial.suggest_int(\"num_leaves\", 15, 255)\n",
        "    min_child_samples = trial.suggest_int(\"min_child_samples\", 5, 100)\n",
        "    min_split_gain = trial.suggest_float(\"min_split_gain\", 0.0, 1.0)\n",
        "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
        "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True)\n",
        "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True)\n",
        "\n",
        "    # Conditional parameters\n",
        "    if boosting_type in ['goss', 'dart']:\n",
        "        subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
        "    else:\n",
        "        subsample = 1.0\n",
        "\n",
        "    if boosting_type == 'dart':\n",
        "        subsample_freq = trial.suggest_int(\"subsample_freq\", 1, 10)\n",
        "        drop_rate = trial.suggest_float(\"drop_rate\", 0.05, 0.5)\n",
        "        skip_drop = trial.suggest_float(\"skip_drop\", 0.3, 0.7)\n",
        "    else:\n",
        "        subsample_freq = 0\n",
        "        drop_rate = 0.1\n",
        "        skip_drop = 0.5\n",
        "\n",
        "    # TimeSeriesSplit\n",
        "    cv = TimeSeriesSplit(n_splits=5)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train)):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        # Chỉ lấy target hiện tại\n",
        "        y_tr_single = y_tr.iloc[:, target_idx] if len(y_tr.shape) > 1 else y_tr\n",
        "        y_val_single = y_val.iloc[:, target_idx] if len(y_val.shape) > 1 else y_val\n",
        "\n",
        "        try:\n",
        "            # Build encoding pipeline với các parameters được tuning\n",
        "            encoding_pipeline = pl.build_encoding_pipeline(\n",
        "                is_category=conditions_is_category,\n",
        "                encoding_method_condition=encoding_method_condition,\n",
        "                n_seasons=n_seasons,\n",
        "                n_quantiles=n_quantiles\n",
        "            )\n",
        "\n",
        "            # Override is_category cho từng component\n",
        "            encoding_pipeline.named_steps['season_encode'].is_category = season_is_category\n",
        "            encoding_pipeline.named_steps['wind_encode'].is_category = wind_is_category\n",
        "\n",
        "            # Apply encoding\n",
        "            X_tr_encoded = encoding_pipeline.fit_transform(X_tr, y_tr_single)\n",
        "            X_val_encoded = encoding_pipeline.transform(X_val)\n",
        "\n",
        "            # LGBM model với early stopping\n",
        "            lgbm_params = {\n",
        "                'boosting_type': boosting_type,\n",
        "                'objective': 'regression',\n",
        "                'learning_rate': learning_rate,\n",
        "                'n_estimators': n_estimators,\n",
        "                'max_depth': max_depth,\n",
        "                'num_leaves': num_leaves,\n",
        "                'min_child_samples': min_child_samples,\n",
        "                'min_split_gain': min_split_gain,\n",
        "                'colsample_bytree': colsample_bytree,\n",
        "                'reg_alpha': reg_alpha,\n",
        "                'reg_lambda': reg_lambda,\n",
        "                'subsample': subsample,\n",
        "                'subsample_freq': subsample_freq,\n",
        "                'random_state': 42,\n",
        "                'n_jobs': 1,\n",
        "                'verbosity': -1\n",
        "            }\n",
        "\n",
        "            # Thêm params cho dart\n",
        "            if boosting_type == 'dart':\n",
        "                lgbm_params['drop_rate'] = drop_rate\n",
        "                lgbm_params['skip_drop'] = skip_drop\n",
        "\n",
        "            lgbm = LGBMRegressor(**lgbm_params)\n",
        "\n",
        "            # Fit với early stopping\n",
        "            lgbm.fit(\n",
        "                X_tr_encoded, y_tr_single,\n",
        "                eval_set=[(X_val_encoded, y_val_single)],\n",
        "                eval_metric='rmse',\n",
        "                callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
        "            )\n",
        "\n",
        "            y_pred_val = lgbm.predict(X_val_encoded)\n",
        "            result = evaluate(y_val_single, y_pred_val)\n",
        "            rmse = result['RMSE']\n",
        "            rmse_scores.append(rmse)\n",
        "\n",
        "            # Báo cho Optuna biết tiến độ trial để pruning\n",
        "            trial.report(rmse, step=fold_idx)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in trial: {e}\")\n",
        "            return float('inf')\n",
        "\n",
        "    mean_rmse = np.mean(rmse_scores)\n",
        "\n",
        "    # Log lên ClearML\n",
        "    logger_lgbm.report_scalar(\n",
        "        title=f'Optuna Tuning - LGBM [{target_name}]',\n",
        "        series='Trial RMSE',\n",
        "        value=mean_rmse,\n",
        "        iteration=trial.number\n",
        "    )\n",
        "\n",
        "    params_table = pd.DataFrame([{\n",
        "        \"target\": target_name,\n",
        "        \"boosting_type\": boosting_type,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"n_estimators\": n_estimators,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"num_leaves\": num_leaves,\n",
        "        \"encoding_method\": encoding_method_condition,\n",
        "        \"n_seasons\": n_seasons,\n",
        "        \"n_quantiles\": n_quantiles\n",
        "    }])\n",
        "    logger_lgbm.report_table(\n",
        "        title=f\"Trial {trial.number} - {target_name}\",\n",
        "        series=\"params\",\n",
        "        iteration=trial.number,\n",
        "        table_plot=params_table\n",
        "    )\n",
        "\n",
        "    return mean_rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e6d4e1",
      "metadata": {
        "id": "f5e6d4e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 2. Hàm helper cho LGBM (CẬP NHẬT) ===\n",
        "def extract_lgbm_params(params):\n",
        "    lgbm_params = {\n",
        "        'boosting_type': params['boosting_type'],\n",
        "        'objective': 'regression',\n",
        "        'learning_rate': params['learning_rate'],\n",
        "        'n_estimators': params['n_estimators'],\n",
        "        'max_depth': params['max_depth'],\n",
        "        'num_leaves': params['num_leaves'],\n",
        "        'min_child_samples': params['min_child_samples'],\n",
        "        'min_split_gain': params['min_split_gain'],\n",
        "        'colsample_bytree': params['colsample_bytree'],\n",
        "        'reg_alpha': params['reg_alpha'],\n",
        "        'reg_lambda': params['reg_lambda'],\n",
        "        'random_state': 42,\n",
        "        'n_jobs': 1,\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    # Conditional parameters\n",
        "    if params['boosting_type'] in ['goss', 'dart']:\n",
        "        lgbm_params['subsample'] = params['subsample']\n",
        "\n",
        "    if params['boosting_type'] == 'dart':\n",
        "        lgbm_params['subsample_freq'] = params['subsample_freq']\n",
        "        lgbm_params['drop_rate'] = params.get('drop_rate', 0.1)\n",
        "        lgbm_params['skip_drop'] = params.get('skip_drop', 0.5)\n",
        "\n",
        "    return lgbm_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c332cefa",
      "metadata": {
        "id": "c332cefa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 3. Tune riêng cho từng target với Pruner ===\n",
        "best_lgbm_models_per_target = {}\n",
        "best_lgbm_params_per_target = {}\n",
        "encoding_pipelines_per_target = {}\n",
        "\n",
        "# Cấu hình Pruner\n",
        "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=2, interval_steps=1)\n",
        "\n",
        "# Tắt logging\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "for idx, target_name in enumerate(y_train.columns):\n",
        "    print(f\"Tuning LGBM for target: {target_name} ({idx + 1}/{len(y_train.columns)})\")\n",
        "\n",
        "    # Tạo study riêng cho mỗi target với pruner\n",
        "    study = optuna.create_study(\n",
        "        direction='minimize',\n",
        "        sampler=optuna.samplers.TPESampler(seed=42),\n",
        "        pruner=pruner  # THÊM PRUNER\n",
        "    )\n",
        "\n",
        "    study.optimize(\n",
        "        lambda trial: objective_lgbm_per_target(trial, target_name, idx),\n",
        "        n_trials= 50,\n",
        "        show_progress_bar=False,\n",
        "        callbacks=[lambda study, trial: None]\n",
        "    )\n",
        "\n",
        "    # Lưu best params\n",
        "    best_lgbm_params_per_target[target_name] = study.best_trial.params\n",
        "    best_lgbm_params_per_target[target_name]['target_idx'] = idx\n",
        "\n",
        "    # Build final encoding pipeline\n",
        "    encoding_pipeline = build_final_encoding_pipeline(study.best_trial.params)\n",
        "\n",
        "    # Override is_category cho từng component\n",
        "    encoding_pipeline.named_steps['season_encode'].is_category = study.best_trial.params['season_is_category']\n",
        "    encoding_pipeline.named_steps['wind_encode'].is_category = study.best_trial.params['wind_is_category']\n",
        "\n",
        "    # Apply encoding trên toàn bộ training data\n",
        "    X_train_encoded = encoding_pipeline.fit_transform(\n",
        "        X_train,\n",
        "        y_train.iloc[:, idx] if len(y_train.shape) > 1 else y_train\n",
        "    )\n",
        "\n",
        "    # Build và train final LGBM model với early stopping\n",
        "    best_lgbm = LGBMRegressor(**extract_lgbm_params(study.best_trial.params))\n",
        "\n",
        "    # Chia train/val cho early stopping\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_tr_final, X_val_final, y_tr_final, y_val_final = train_test_split(\n",
        "        X_train_encoded,\n",
        "        y_train.iloc[:, idx] if len(y_train.shape) > 1 else y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        shuffle=False  # Giữ thứ tự time series\n",
        "    )\n",
        "\n",
        "    best_lgbm.fit(\n",
        "        X_tr_final, y_tr_final,\n",
        "        eval_set=[(X_val_final, y_val_final)],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
        "    )\n",
        "\n",
        "    best_lgbm_models_per_target[target_name] = {\n",
        "        'model': best_lgbm,\n",
        "        'encoding_pipeline': encoding_pipeline\n",
        "    }\n",
        "\n",
        "    encoding_pipelines_per_target[target_name] = encoding_pipeline\n",
        "\n",
        "    # Log kết quả\n",
        "    logger_lgbm.report_scalar(\n",
        "        title='Best RMSE per Target - LGBM',\n",
        "        series=target_name,\n",
        "        value=study.best_value,\n",
        "        iteration=idx\n",
        "    )\n",
        "\n",
        "\n",
        "    # SỬA PHẦN NÀY: Thêm thông tin is_category vào print\n",
        "    print(f\" {target_name} - Best RMSE: {study.best_value:.4f}\")\n",
        "    print(f\" {target_name} - Best boosting: {study.best_trial.params['boosting_type']}\")\n",
        "    print(f\" {target_name} - Encoding: {study.best_trial.params['encoding_method_condition']}\")\n",
        "    print(f\" {target_name} - Seasons: {study.best_trial.params['n_seasons']}\")\n",
        "    print(f\" {target_name} - Conditions is_category: {study.best_trial.params['conditions_is_category']}\")\n",
        "    print(f\" {target_name} - Season is_category: {study.best_trial.params['season_is_category']}\")\n",
        "    print(f\" {target_name} - Wind is_category: {study.best_trial.params['wind_is_category']}\")\n",
        "    print(f\" {target_name} - Quantiles: {study.best_trial.params['n_quantiles']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Khôi phục logging\n",
        "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "# In summary tất cả parameters\n",
        "print(\"\\n=== BEST PARAMETERS SUMMARY ===\")\n",
        "for target_name in y_train.columns:\n",
        "    params = best_lgbm_params_per_target[target_name]\n",
        "    print(f\"\\n{target_name}:\")\n",
        "    print(f\"  RMSE: {study.best_value:.4f}\")\n",
        "    print(f\"  Boosting: {params['boosting_type']}\")\n",
        "    print(f\"  Encoding: {params['encoding_method_condition']}\")\n",
        "    print(f\"  Seasons: {params['n_seasons']}\")\n",
        "    print(f\"  Quantiles: {params['n_quantiles']}\")\n",
        "    print(f\"  Conditions categorical: {params['conditions_is_category']}\")\n",
        "    print(f\"  Season categorical: {params['season_is_category']}\")\n",
        "    print(f\"  Wind categorical: {params['wind_is_category']}\")\n",
        "    print(f\"  Learning rate: {params['learning_rate']:.4f}\")\n",
        "    print(f\"  Max depth: {params['max_depth']}\")\n",
        "    print(f\"  Num leaves: {params['num_leaves']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91efdecb",
      "metadata": {
        "id": "91efdecb"
      },
      "source": [
        "#### C. Training Final Model với hyper parameter và đánh giá cuối cùng trên Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6636f14c",
      "metadata": {
        "id": "6636f14c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 4. Tạo MultiOutput wrapper cho LGBM ===\n",
        "class CustomLGBMMultiOutputRegressor:\n",
        "    def __init__(self, models_per_target):\n",
        "        self.models_per_target = models_per_target\n",
        "        self.target_names = list(models_per_target.keys())\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for target_name, model_info in self.models_per_target.items():\n",
        "            # Apply encoding\n",
        "            X_encoded = model_info['encoding_pipeline'].transform(X)\n",
        "            # Predict\n",
        "            pred = model_info['model'].predict(X_encoded).reshape(-1, 1)\n",
        "            predictions.append(pred)\n",
        "        return np.hstack(predictions)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {\"models_per_target\": self.models_per_target}\n",
        "\n",
        "# Tạo final model\n",
        "final_lgbm_multi_model = CustomLGBMMultiOutputRegressor(best_lgbm_models_per_target)\n",
        "\n",
        "# === 5. Đánh giá final model ===\n",
        "y_pred_test_lgbm = final_lgbm_multi_model.predict(X_test)\n",
        "y_pred_train_lgbm = final_lgbm_multi_model.predict(X_train)\n",
        "\n",
        "final_test_metrics_lgbm = evaluate_multi_output(y_test, y_pred_test_lgbm)\n",
        "final_train_metrics_lgbm = evaluate_multi_output(y_train, y_pred_train_lgbm)\n",
        "\n",
        "print(\"LGBM Final Model - Test metrics (average):\", final_test_metrics_lgbm[\"average\"])\n",
        "print(\"LGBM Final Model - Test metrics (perday):\", final_test_metrics_lgbm[\"per_day\"])\n",
        "print()\n",
        "print(\"LGBM Final Model - Train metrics (average):\", final_train_metrics_lgbm[\"average\"])\n",
        "print(\"LGBM Final Model - Train metrics (perday):\", final_train_metrics_lgbm[\"per_day\"])\n",
        "\n",
        "# === 6. Log final results ===\n",
        "task_lgbm.upload_artifact(\"Best LGBM Parameters Per Target\", best_lgbm_params_per_target)\n",
        "task_lgbm.upload_artifact(\"LGBM Final Model - Test Metrics\", final_test_metrics_lgbm)\n",
        "task_lgbm.upload_artifact(\"LGBM Final Model - Train Metrics\", final_train_metrics_lgbm)\n",
        "\n",
        "# === 7. Lưu models ===\n",
        "lgbm_models_path = r\"models/LGBM_models_per_target.pkl\"\n",
        "joblib.dump({\n",
        "    'models': best_lgbm_models_per_target,\n",
        "    'params': best_lgbm_params_per_target,\n",
        "    'final_model': final_lgbm_multi_model\n",
        "}, lgbm_models_path)\n",
        "\n",
        "print(\"=== LGBM TUNING COMPLETED ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46809134",
      "metadata": {
        "id": "46809134"
      },
      "source": [
        "#### T bảo, nếu két quả tuning tệ hơn tune_lgb thì lấy cái tune_lgb cũ nhé (kết quả tệ cũng có thể do mình drop hết base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a2a827",
      "metadata": {
        "id": "31a2a827"
      },
      "outputs": [],
      "source": [
        "# Defaut Goss\n",
        "tune_lgb = LGBMRegressor(\n",
        "    boosting_type='goss',\n",
        "    objective= 'regression', # loss function\n",
        "    colsample_bytree=0.7688738230630878,\n",
        "    learning_rate=0.015433744772417535,\n",
        "    max_depth= 4,\n",
        "    min_child_samples=50,\n",
        "    min_split_gain=0.4084759794499262,\n",
        "    n_estimators=417,\n",
        "    num_leaves=128,\n",
        "    reg_alpha=0.008,\n",
        "    reg_lambda=0.008,\n",
        "    # subsample=0.9098920662929666,\n",
        "    # subsample_freq= 10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_grad = MultiOutputRegressor(estimator=tune_lgb, n_jobs=-1)\n",
        "\n",
        "# 2️⃣ Time series cross-validation (chỉ trên tập train)\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "cv_scores = []  # lưu kết quả trung bình của mỗi fold\n",
        "\n",
        "print(\"=== Time Series Cross-Validation ===\")\n",
        "\n",
        "fold_idx = 1\n",
        "for train_idx, val_idx in tscv.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Huấn luyện mô hình\n",
        "    model_grad.fit(X_tr, y_tr)\n",
        "    y_pred_val = model_grad.predict(X_val)\n",
        "\n",
        "    # Đánh giá\n",
        "    metrics_val = evaluate_multi_output(y_val, y_pred_val)\n",
        "    avg_val = metrics_val[\"average\"]\n",
        "    cv_scores.append(avg_val)\n",
        "\n",
        "    print(f\"\\nFold {fold_idx} validation metrics:\")\n",
        "    print(avg_val)\n",
        "    fold_idx += 1\n",
        "\n",
        "# 3️⃣ Tổng hợp kết quả cross-validation\n",
        "cv_df = pd.DataFrame(cv_scores)\n",
        "print(\"\\n=====> Cross-validation (Time Series) trung bình:\")\n",
        "print(cv_df.mean())\n",
        "\n",
        "print(\"\\n=====> Cross-validation (Time Series) độ lệch chuẩn (variance):\")\n",
        "print(cv_df.std())\n",
        "\n",
        "# Sau khi bạn thấy mô hình ổn định qua các fold,\n",
        "# bạn huấn luyện lại trên toàn bộ tập train rồi đánh giá 1 lần trên test (dữ liệu tương lai thật).\n",
        "\n",
        "# 4️⃣ Huấn luyện lại toàn bộ tập train sau khi CV\n",
        "model_grad.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 5️⃣ Đánh giá cuối cùng trên tập train\n",
        "y_pred_train = model_grad.predict(X_train)\n",
        "defGrad_train_metrics = evaluate_multi_output(y_train, y_pred_train)\n",
        "\n",
        "print(\"\\n=====> Train metrics (trung bình):\", defGrad_train_metrics[\"average\"])\n",
        "print(\"Train metrics (chi tiết từng ngày):\", defGrad_train_metrics[\"per_day\"])\n",
        "\n",
        "\n",
        "# 5️⃣ Đánh giá cuối cùng trên tập test\n",
        "y_pred_test = model_grad.predict(X_test)\n",
        "defGrad_test_metrics = evaluate_multi_output(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\n=====> Test metrics (trung bình):\", defGrad_test_metrics[\"average\"])\n",
        "print(\"Test metrics (chi tiết từng ngày):\", defGrad_test_metrics[\"per_day\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54289a69",
      "metadata": {
        "id": "54289a69"
      },
      "outputs": [],
      "source": [
        "# Sau khi bạn thấy mô hình ổn định qua các fold,\n",
        "# bạn huấn luyện lại trên toàn bộ tập train rồi đánh giá 1 lần trên test (dữ liệu tương lai thật).\n",
        "\n",
        "# 4️⃣ Huấn luyện lại toàn bộ tập train sau khi CV\n",
        "model_grad.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 5️⃣ Đánh giá cuối cùng trên tập train\n",
        "y_pred_train = model_grad.predict(X_train)\n",
        "defGrad_train_metrics = evaluate_multi_output(y_train, y_pred_train)\n",
        "\n",
        "print(\"\\n=====> Train metrics (trung bình):\", defGrad_train_metrics[\"average\"])\n",
        "print(\"Train metrics (chi tiết từng ngày):\", defGrad_train_metrics[\"per_day\"])\n",
        "\n",
        "\n",
        "# 5️⃣ Đánh giá cuối cùng trên tập test\n",
        "y_pred_test = model_grad.predict(X_test)\n",
        "defGrad_test_metrics = evaluate_multi_output(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\n=====> Test metrics (trung bình):\", defGrad_test_metrics[\"average\"])\n",
        "print(\"Test metrics (chi tiết từng ngày):\", defGrad_test_metrics[\"per_day\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c94032e",
      "metadata": {
        "id": "0c94032e"
      },
      "source": [
        "### 3. Bảng so sánh kết quả 2 model (so sánh chung chung để chốt chọn model nào - lgb - sau đó mình mới phân tích cụ thể kết quả ở mục sau)\n",
        "- Nhàn lên cho t cái form so sánh những gì (các chỉ số average, perday, time) - Hoặc chụp ảnh dùng cái chức năng so sánh của ClearML - Hoặc cả 2\n",
        "- Xong Nhàn với Hoàng train ra được model tốt nhất của linear với LGB rồi thì điền vào đây nhé (mấy cái metric căn bản có lưu trên clearml)\n",
        "- Kết luận: Chọn model LGB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5714134",
      "metadata": {
        "id": "c5714134"
      },
      "source": [
        "### 4. Đánh giá và Giải thích cụ thể kết quả của model (LGB) - Hoàng\n",
        "bn chờ t cập nhật format biểu đồ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17955db",
      "metadata": {
        "id": "f17955db"
      },
      "outputs": [],
      "source": [
        "# Giả sử y_test có index datetime\n",
        "y_test.index = pd.to_datetime(y_test.index)\n",
        "\n",
        "# Tạo DataFrame/Series cho y_pred với index từ y_test\n",
        "y_pred_with_index = pd.DataFrame(y_pred_test, index=y_test.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a98206f",
      "metadata": {
        "id": "4a98206f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_separate_horizons(y_test, y_pred_test, figsize=(16, 6)):\n",
        "    \"\"\"\n",
        "    Vẽ 5 biểu đồ riêng biệt cho 5 horizons.\n",
        "    Mỗi biểu đồ hiển thị dữ liệu thực (y_true) và dự đoán (y_pred)\n",
        "    với màu và kiểu đường dễ phân biệt.\n",
        "    \"\"\"\n",
        "\n",
        "    # Kiểm tra input\n",
        "    assert y_test.shape[1] == 5, \"y_test phải có 5 columns\"\n",
        "    assert y_pred_test.shape[1] == 5, \"y_pred_test phải có 5 columns\"\n",
        "    assert len(y_test) == len(y_pred_test), \"Số samples phải khớp\"\n",
        "\n",
        "    horizon_names = [\n",
        "        'Horizon 1 (Next Day)',\n",
        "        'Horizon 2 (2 Days Ahead)',\n",
        "        'Horizon 3 (3 Days Ahead)',\n",
        "        'Horizon 4 (4 Days Ahead)',\n",
        "        'Horizon 5 (5 Days Ahead)'\n",
        "    ]\n",
        "\n",
        "    # Màu nhẹ cho Actual, màu đậm cho Predict\n",
        "    true_color = \"#1f77b4\"   # Xanh dương dịu\n",
        "    pred_color = \"#ff7f0e\"   # Cam dịu\n",
        "\n",
        "    for i in range(5):\n",
        "        plt.figure(figsize=figsize)\n",
        "\n",
        "        y_true_horizon = y_test.iloc[:, i]\n",
        "        y_pred_horizon = y_pred_test[:, i]\n",
        "        dates = y_test.index\n",
        "\n",
        "        # Metrics\n",
        "        rmse = np.sqrt(np.mean((y_true_horizon - y_pred_horizon) ** 2))\n",
        "        mae = np.mean(np.abs(y_true_horizon - y_pred_horizon))\n",
        "        r2 = 1 - np.sum((y_true_horizon - y_pred_horizon) ** 2) / np.sum((y_true_horizon - np.mean(y_true_horizon)) ** 2)\n",
        "\n",
        "        # --- Vẽ biểu đồ ---\n",
        "        plt.plot(\n",
        "            dates, y_true_horizon,\n",
        "            label='Actual Temperature',\n",
        "            color=true_color,\n",
        "            linewidth=1\n",
        "        )\n",
        "\n",
        "        plt.plot(\n",
        "            dates, y_pred_horizon,\n",
        "            label='Predicted Temperature',\n",
        "            color=pred_color,\n",
        "            linewidth=1\n",
        "        )\n",
        "\n",
        "        # --- Tuỳ chỉnh ---\n",
        "        plt.title(\n",
        "            f'{horizon_names[i]}\\nRMSE: {rmse:.2f}°C | MAE: {mae:.2f}°C | R²: {r2:.3f}',\n",
        "            fontsize=13, fontweight='bold', pad=20\n",
        "        )\n",
        "        plt.ylabel('Temperature (°C)', fontsize=11)\n",
        "        plt.xlabel('Date', fontsize=11)\n",
        "        plt.legend(fontsize=11, frameon=False)\n",
        "        plt.grid(True, linestyle=':', alpha=0.5)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "plot_separate_horizons(y_test, y_pred_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f45c9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "32f45c9a",
        "outputId": "1fba150c-100c-4776-d116-e08a26226a20"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4030441546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mplot_rmse_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ],
      "source": [
        "def plot_rmse_over_time(y_test, y_pred_test, window=7, figsize=(14, 5)):\n",
        "    \"\"\"\n",
        "    Vẽ 5 biểu đồ riêng biệt cho RMSE theo thời gian (rolling window),\n",
        "    với cùng đơn vị (cố định trục Y).\n",
        "    \"\"\"\n",
        "\n",
        "    # Kiểm tra input\n",
        "    assert y_test.shape[1] == 5, \"y_test phải có 5 columns\"\n",
        "    assert y_pred_test.shape[1] == 5, \"y_pred_test phải có 5 columns\"\n",
        "    assert len(y_test) == len(y_pred_test), \"Số samples phải khớp\"\n",
        "\n",
        "    horizon_names = [\n",
        "        'Horizon 1 (Next Day)',\n",
        "        'Horizon 2 (2 Days Ahead)',\n",
        "        'Horizon 3 (3 Days Ahead)',\n",
        "        'Horizon 4 (4 Days Ahead)',\n",
        "        'Horizon 5 (5 Days Ahead)'\n",
        "    ]\n",
        "\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "    dates = y_test.index\n",
        "\n",
        "    # Tính rolling RMSE cho tất cả horizons để tìm giới hạn trục Y chung\n",
        "    all_rmse = []\n",
        "    for i in range(5):\n",
        "        y_true = y_test.iloc[:, i]\n",
        "        y_pred = y_pred_test[:, i]\n",
        "        rolling_rmse = np.sqrt(((y_true - y_pred)**2).rolling(window).mean())\n",
        "        all_rmse.append(rolling_rmse)\n",
        "\n",
        "    # Tính min/max chung cho toàn bộ 5 biểu đồ\n",
        "    all_values = pd.concat(all_rmse)\n",
        "    ymin, ymax = all_values.min(), all_values.max()\n",
        "    margin = (ymax - ymin) * 0.1  # thêm khoảng trống 10%\n",
        "    ymin -= margin\n",
        "    ymax += margin\n",
        "\n",
        "    # Vẽ từng biểu đồ\n",
        "    for i in range(5):\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.plot(dates, all_rmse[i], color=colors[i], linewidth=1.8)\n",
        "\n",
        "        mean_rmse = all_rmse[i].mean()\n",
        "        plt.axhline(mean_rmse, color='gray', linestyle='--', linewidth=1,\n",
        "                    label=f'Mean RMSE = {mean_rmse:.2f}')\n",
        "\n",
        "        plt.title(f'{horizon_names[i]} - Rolling RMSE (window={window} days)',\n",
        "                  fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Date', fontsize=12)\n",
        "        plt.ylabel('RMSE (°C)', fontsize=12)\n",
        "        plt.ylim(ymin, ymax)  # <-- cố định trục Y\n",
        "        plt.legend(fontsize=10, frameon=False)\n",
        "        plt.grid(True, linestyle=':', alpha=0.5)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "plot_rmse_over_time(y_test, y_pred_test, window=7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed07c359",
      "metadata": {
        "id": "ed07c359"
      },
      "source": [
        "### 5. UI + Model Maintainence + Realtime predict - Sương Mai\n",
        "- Sử dụng Gradio\n",
        "- Trả lời ngắn gọn câu hỏi của thầy \"\"The common sense is, if you train model and use it to predict day by day, at some point, the performance will downgrade. When you should retrain your model?\"\"\n",
        "<br> Lí do phải retrain là gì: ngắn gọn\n",
        "<br> Ngắn gọn cơ chế maintainnence: có 2 điều kiện khi RMSE vướt ngưỡng + 90 ngày maintain một lần\n",
        "\n",
        "- Sửa lại READ.ME cái mục cấu trúc project + Vẽ Biểu đồ (trên Canva,... tuỳ) về cấu trúc tổng thể, cách hoạt động của các file (VD như File Monitoring vẽ if/ else block Yes điều kiện retrain => mũi tên file Model_training, vv... )\n",
        "\n",
        "- Link Video sử dụng UI để dự đoán realtime + show Cloud trên ClearML của mình + kèm link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df7ce3f2",
      "metadata": {
        "id": "df7ce3f2"
      },
      "source": [
        "### 6. Preprocessing/ Feature Enginering/ Tuning/ Training / Đánh giá kết quả Hourly (dùng luôn lgb)\n",
        "- Vẽ tổng quát Biểu đồ các step: input, output đầu ra mỗi step, thứ từ các step mũi tên như nào (Vẽ trên canva hay ppt r cop lại đây)\n",
        "- Preprocessing:\n",
        "   + Input: dữ liệu hourly bao nhiêu row, bao cột\n",
        "   + Drop columns nào, làm gì, ... (Nói là LGB nên cũng không cần xử lí nhiều, chủ yếu bỏ mấy cột thừa)\n",
        "   + Output: ...\n",
        "- Feature Engineering:\n",
        "   + Feature Engineering Hourly:\n",
        "      - Input: từ Preprocessing (đang bao nhiêu row hourly, bao nhiêu column)\n",
        "      - Giải thích qua làm gì:\n",
        "      - Output: (Còn bao nhiêu cột Daily, Tạo bao nhiêu columns: ngắn gọn cho t với nhóm nhiệt độ thì lấy aggregate mean, max, min, với theo chu kì trong ngày, Nhóm mặt trời thì chỉ lấy mean, với cao nhất trong ngày, ... vv)\n",
        "   + Feature Engineering Daily Adjusted to new feature in Hourly:\n",
        "      - Input:\n",
        "      - Giải thích qua làm gì, thêm cái gì đối với feature mới từ hourly\n",
        "      - Output:\n",
        "\n",
        "- Tuning/ Training:\n",
        "   + Cho t cái bản tóm tắt metric so sánh (Before training chỉ số các fold, Sau training kết quả train/ test average, perday so sánh với Daily LGB luôn)\n",
        "   + Trực quan hoá bằng biểu đồ đường, biểu đồ cột so sánh các metric RMSE, MAE, R2 nhìn cho dễ - đừng vẽ mỗi cái một dòng khó nhìn lắm, để hết vào 1 cái khung figure, rồi chia row, column trong đấy để biểu đồ vào\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcf6357",
      "metadata": {
        "id": "cbcf6357"
      },
      "source": [
        "### 7. ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3682e0",
      "metadata": {
        "id": "ae3682e0"
      },
      "outputs": [],
      "source": [
        "def lưu_nháp_kệ_đi():\n",
        "   pass\n",
        "   # hàm encoding conditions\n",
        "   # condition = dp.ConditionsEncoder(is_category = False, encoding_method='target') # False tốt hơn\n",
        "   # X_train = condition.fit_transform(X_train, X_train['temp'])\n",
        "   # X_test = condition.transform(X_test)\n",
        "\n",
        "   # # hàm encoding season\n",
        "   # season = dp.SeasonClassifier(n_seasons=5, is_category = False) # False tốt hơn\n",
        "   # X_train = season.fit_transform(X_train, X_train['temp'])\n",
        "   # X_test = season.transform(X_test)\n",
        "\n",
        "   # # hàm encoding wind\n",
        "   # wind = dp.WindCategoryEncoder(is_category= False, n_quantiles= 4) # nếu không dùng kết hợp với condtions thì False tốt hơn\n",
        "   # X_train = wind.fit_transform(X_train, X_train['temp'])\n",
        "   # X_test = wind.transform(X_test)\n",
        "\n",
        "   # # Nháp của t kệ đi\n",
        "   # # Chạy code so sánh Numeric season vs Category season\n",
        "   # # hàm encoding conditions\n",
        "   # condition = dp.ConditionsEncoder(is_category = True, encoding_method='target') # False tốt hơn\n",
        "   # train_feat = condition.fit_transform(train_feat, train_feat['temp'])\n",
        "   # test_feat = condition.transform(test_feat)\n",
        "\n",
        "   # # hàm encoding season\n",
        "   # season = dp.SeasonClassifier(n_seasons=5, is_category = True) # False tốt hơn\n",
        "   # train_feat = season.fit_transform(train_feat, train_feat['temp'])\n",
        "   # test_feat = season.transform(test_feat)\n",
        "\n",
        "   # # hàm encoding wind\n",
        "   # wind = dp.WindCategoryEncoder(is_category= True) # nếu không dùng kết hợp với condtions thì False tốt hơn\n",
        "   # train_feat = wind.fit_transform(train_feat, train_feat['temp'])\n",
        "   # test_feat = wind.transform(test_feat)\n",
        "\n",
        "   # # Chia X, y riêng biệt\n",
        "   # X_train = train_feat.drop(columns= target_col)\n",
        "   # y_train = train_feat[target_col]\n",
        "\n",
        "   # X_test = test_feat.drop(columns= target_col)\n",
        "   # y_test = test_feat[target_col]\n",
        "\n",
        "   # print(f\"Train: {X_train.shape, y_train.shape}, Test: {X_test.shape, y_test.shape}\")\n",
        "\n",
        "   # # Chạy code so sánh Numeric wind_cateogry vs Category wind_category\n",
        "\n",
        "\n",
        "   # # Chạy code so sánh Numeric conditions vs Category conditions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   # from optuna.pruners import MedianPruner\n",
        "   # from lightgbm import early_stopping\n",
        "\n",
        "   # # ===  Tạo hàm objective ===\n",
        "   # def objective(trial):\n",
        "   #     boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart'])\n",
        "\n",
        "   #     params = {\n",
        "   #         'boosting_type': boosting_type,\n",
        "   #         'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "   #         'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10.0, log=True),\n",
        "   #         'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.3),\n",
        "   #         'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "   #         'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 1.0, log=True),\n",
        "   #         'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 1.0, log=True),\n",
        "   #         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "   #         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "   #         'subsample_freq': trial.suggest_int('subsample_freq', 1, 7),\n",
        "   #         'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
        "   #         'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "   #         'max_bin': trial.suggest_int('max_bin', 64, 512),\n",
        "   #         'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "\n",
        "   #         'objective': 'regression',\n",
        "   #         'metric': 'rmse',\n",
        "   #         'random_state': 42,\n",
        "   #         'n_jobs': -1,\n",
        "   #         'verbosity': -1  #\n",
        "   #     }\n",
        "\n",
        "   #     if boosting_type == 'dart':\n",
        "   #         params['drop_rate'] = trial.suggest_float('drop_rate', 0.05, 0.5)\n",
        "   #         params['skip_drop'] = trial.suggest_float('skip_drop', 0.3, 0.7)\n",
        "\n",
        "   #     # === TimeSeriesSplit CV ===\n",
        "   #     cv = TimeSeriesSplit(n_splits=5)\n",
        "   #     rmse_scores = []\n",
        "\n",
        "   #     for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train_sel)):\n",
        "   #         X_tr, X_val = X_train_sel.iloc[train_idx], X_train_sel.iloc[val_idx]\n",
        "   #         y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "   #         # Fit riêng cho từng cột output\n",
        "   #         models_fold = {}\n",
        "   #         y_pred_val = pd.DataFrame(index=y_val.index, columns=y_val.columns)\n",
        "\n",
        "   #         for col in y_train.columns:\n",
        "   #             model = LGBMRegressor(**params)\n",
        "   #             model.fit(\n",
        "   #                 X_tr, y_tr[col],\n",
        "   #                 eval_set=[(X_val, y_val[col])],\n",
        "   #                 eval_metric='rmse',\n",
        "   #                 callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
        "\n",
        "   #             )\n",
        "   #             models_fold[col] = model\n",
        "   #             y_pred_val[col] = model.predict(X_val)\n",
        "\n",
        "   #         metrics = evaluate_multi_output(y_val, y_pred_val)\n",
        "   #         rmse_fold = metrics[\"average\"][\"RMSE\"]\n",
        "   #         rmse_scores.append(rmse_fold)\n",
        "\n",
        "   #         # Báo cho Optuna biết tiến độ trial\n",
        "   #         trial.report(rmse_fold, step=fold_idx)\n",
        "   #         if trial.should_prune():\n",
        "   #             raise optuna.TrialPruned()\n",
        "\n",
        "   #     mean_rmse = np.mean(rmse_scores)\n",
        "   #     return mean_rmse\n",
        "\n",
        "   # # === 3️ Cấu hình Pruner ===\n",
        "   # pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=2, interval_steps=1)\n",
        "\n",
        "   # # === 4 Chạy Optuna Study ===\n",
        "   # sampler = optuna.samplers.TPESampler(seed=42)\n",
        "   # study_grad = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\n",
        "   # study_grad.optimize(objective, n_trials=500, show_progress_bar=True)\n",
        "\n",
        "   # # === 5️ In kết quả ===\n",
        "   # print(\" Best parameters:\", study_grad.best_trial.params)\n",
        "   # print(\" Best RMSE (Optuna CV):\", study_grad.best_value)\n",
        "\n",
        "   # # === 6️ Fit lại với best params cho từng output ===\n",
        "   # best_params = study_grad.best_trial.params\n",
        "   # final_models = {}\n",
        "   # y_pred_train = pd.DataFrame(index=y_train.index, columns=y_train.columns)\n",
        "   # y_pred_test = pd.DataFrame(index=y_test.index, columns=y_test.columns)\n",
        "\n",
        "   # for col in y_train.columns:\n",
        "   #     model = LGBMRegressor(**best_params)\n",
        "   #     model.fit(\n",
        "   #         X_train_sel, y_train[col],\n",
        "   #         eval_set=[(X_test_sel, y_test[col])],\n",
        "   #         eval_metric='rmse',\n",
        "   #         callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
        "   #     )\n",
        "\n",
        "   #     final_models[col] = model\n",
        "   #     y_pred_train[col] = model.predict(X_train_sel)\n",
        "   #     y_pred_test[col] = model.predict(X_test_sel)\n",
        "\n",
        "   # # Evaluate\n",
        "   # bestGrad_train_metrics = evaluate_multi_output(y_train, y_pred_train)\n",
        "   # bestGrad_test_metrics = evaluate_multi_output(y_test, y_pred_test)\n",
        "\n",
        "   # print(\"Best Model - Train metrics (average):\", bestGrad_train_metrics[\"average\"])\n",
        "   # print(\"Best Model - Test metrics (average):\", bestGrad_test_metrics[\"average\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}